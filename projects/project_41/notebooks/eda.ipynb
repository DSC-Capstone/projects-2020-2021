{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA Notebook\n",
    "- Table of Content\n",
    "    - Part1. Event Type\n",
    "    - Part2. Text Features\n",
    "    - Part3. EPS Surpriseness \n",
    "    - Part4. Label / Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_config = json.load(open('../config/notebook.json', 'r'))\n",
    "if notebook_config['testing']:\n",
    "    data_dir = '../test/'\n",
    "else:\n",
    "    data_dir = '../data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Reading in the data...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(data_dir + 'processed/feature_encoded_merged_data.pkl')\n",
    "unigrams = pd.read_csv(data_dir + 'processed/model_unigrams.csv')\n",
    "phrases = pd.read_csv(data_dir + 'financial_phrases_sample.txt', sep = '\\t', header = None).head(2107)\n",
    "\n",
    "def select_phrases(phrases):\n",
    "    return phrases[:2107]\n",
    "data['top_phrases'] = data['phrase_vec'].apply(select_phrases)\n",
    "\n",
    "train = data.loc[data['dataset'] == 'train'].copy()\n",
    "val = data.loc[data['dataset'] == 'val'].copy()\n",
    "test = data.loc[data['dataset'] == 'test'].copy()\n",
    "\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Event Type\n",
    "- **Note**: \"event type\" is an important field of every 8K report. Here we treat it as a categorical feature where each 8K report could have multiple event type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "all_events = pd.DataFrame(mlb.fit_transform(data['cleaned_event']),\n",
    "                   columns = mlb.classes_,\n",
    "                   index = data['cleaned_event'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = data.explode('cleaned_event').groupby('cleaned_event').count()['symbol']\n",
    "events = events.reset_index().sort_values(by = ['symbol'], ascending = False).reset_index(drop = True)\n",
    "events = events.rename(columns = {'cleaned_event': 'event', 'symbol': 'count'})\n",
    "events.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Text Features - Unigrams & Phrases from AutoPhrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_percent = [np.array(vector) for vector in train['unigram_vec'].values]\n",
    "uni_count = np.array(uni_percent).sum(axis = 0) \n",
    "uni_percent = uni_count / len(train)\n",
    "\n",
    "phrase_percent = [np.array(vector) for vector in train['top_phrases'].values]\n",
    "phrase_count = np.array(phrase_percent).sum(axis = 0)\n",
    "phrase_percent = phrase_count / len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Top Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams[\"% of 8-K's\"] = uni_percent\n",
    "unigrams[\"freq\"] = uni_count\n",
    "unigrams_freq = unigrams.sort_values(by = 'freq', ascending = False)\n",
    "unigrams_freq.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict(zip(unigrams_freq['unigrams'].values, unigrams_freq['freq'].values))\n",
    "\n",
    "wordcloud = WordCloud(background_color='white', width=800, height=400)\n",
    "wordcloud.generate_from_frequencies(frequencies=d)\n",
    "plt.figure(figsize=(20,15))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "# plt.figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Top Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases[\"% of 8-K's\"] = phrase_percent\n",
    "phrases = phrases.rename(columns = {1: 'phrases'})\n",
    "phrases['freq'] = phrase_count\n",
    "phrases_freq = phrases[['phrases', \"% of 8-K's\", \"freq\"]].sort_values(by = \"% of 8-K's\", ascending = False).reset_index(drop = True)\n",
    "phrases_freq.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict(zip(phrases_freq['phrases'].values, phrases_freq['freq'].values))\n",
    "\n",
    "wordcloud = WordCloud(background_color='white', width=800, height=400)\n",
    "wordcloud.generate_from_frequencies(frequencies=d)\n",
    "plt.figure(figsize=(20,15))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Summary**: From the frequency table and the word-clouds above, we can tell that phrases from AutoPhrase and Investopedia knowledge base is much more meaningful than the top unigrams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. EPS Surpriseness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surprises = data['Surprise(%)'].values\n",
    "lower, upper = np.percentile(surprises, [5, 95])\n",
    "surprises_mid_95 = surprises[(surprises > lower) & (surprises < upper)]\n",
    "\n",
    "sns.distplot(surprises_mid_95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surprises_mid_95_w_label = data[(data['Surprise(%)'] > lower) & (data['Surprise(%)'] < upper)][['Surprise(%)', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 classes\n",
    "sns.histplot(x = 'Surprise(%)', hue = 'target', data = surprises_mid_95_w_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# down V.S.up\n",
    "sns.histplot(x = 'Surprise(%)', hue = 'target', data = surprises_mid_95_w_label.query('target != \"STAY\"'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# down V.S. stay\n",
    "sns.histplot(x = 'Surprise(%)', hue = 'target', data = surprises_mid_95_w_label.query('target != \"UP\"'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# up V.S. stay\n",
    "sns.histplot(x = 'Surprise(%)', hue = 'target', data = surprises_mid_95_w_label.query('target != \"DOWN\"'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Summary**: As we can see in the chart above, the EPS Surpriseness is indeed a pretty good indicator for prediction; however, note that there is also a great number of nearly-zero-surpriseness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Class / Label Dirstibution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Label distribution for three classes in different subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data = [data.groupby(data['target']).count()['symbol'] / data.shape[0],\n",
    "                     train.groupby(train['target']).count()['symbol'] / train.shape[0],\n",
    "                     val.groupby(val['target']).count()['symbol'] / val.shape[0],\n",
    "                     test.groupby(test['target']).count()['symbol'] / test.shape[0]],\n",
    "             index = [\"all_data\", \"train\", \"val\", \"test\"]\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Average price change for each target in different subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data = [data.groupby(data['target']).mean()['targe_price_change'],\n",
    "                     train.groupby(train['target']).mean()['targe_price_change'],\n",
    "                     val.groupby(val['target']).mean()['targe_price_change'],\n",
    "                     test.groupby(test['target']).mean()['targe_price_change']],\n",
    "             index = [\"all_data\", \"train\", \"val\", \"test\"]\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Summary**: As we can see from the tables above, the label distribution is relatively even and balanced for three classes in all subsets; the average price changes for different targets also align with our expectation (i.e. STAY has nearly 0 change, UP has positive change, and DOWN has negative change)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
