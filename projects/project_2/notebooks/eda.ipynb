{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "from IPython.display import Image, display\n",
    "os.chdir('..')\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config/data-params.json') as fh:\n",
    "    data_cfg = json.load(fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 'pol_rightness'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(data_cfg['training_data_path'], 'data.csv')).drop(columns=['Unnamed: 0'])\n",
    "def remove_hashtags_and_ats(x):\n",
    "    return x.replace('#', '').replace('@', '')\n",
    "df['text'] = df['text'].apply(remove_hashtags_and_ats)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[dim].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_DF = 0.000002\n",
    "MIN_DF*df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(stop_words='english')\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "clf = MultinomialNB(fit_prior=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df['text'], df[dim]\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "kf.get_n_splits(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    text_clf = Pipeline([('vect', count_vect), ('tfidf', tfidf_transformer), ('clf', clf)])\n",
    "    text_clf.fit(X_train, y_train)\n",
    "    y_pred = text_clf.predict(X_test)\n",
    "    class_acc = np.mean(y_pred == y_test)\n",
    "    reg_error = np.mean(abs(y_pred - y_test))\n",
    "    print('Class_acc: {}'.format(class_acc))\n",
    "    print('Regression error: {}'.format(reg_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Regression Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_error = np.mean(abs(y_pred - y_test))\n",
    "avg_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in user tweets\n",
    "tweets = {}\n",
    "for tweet_id in data_cfg['tweet_ids']:\n",
    "    path = os.path.join(data_cfg['output_user_data_path'], 'tweet_{}.csv'.format(tweet_id))\n",
    "    tweet = pickle.load(open(path, 'rb'))\n",
    "    tweets[tweet_id] = tweet\n",
    "    for key, value in tweets.items():\n",
    "        for user_id in list(value['user_ids'].keys()):\n",
    "            value['user_ids'][user_id] = pd.read_csv(os.path.join(data_cfg['output_user_data_path'], 'user_{}_tweets.csv'.format(user_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Going through all the users of all the tweets\n",
    "# for tweet_id in tweets.keys():\n",
    "#     user_ids = list(tweets[tweet_id]['user_ids'].keys())\n",
    "#     for user_id in user_ids:\n",
    "#         df = pd.read_csv(os.path.join(data_cfg['output_user_data_path'], 'user_{}_tweets.csv'.format(user_id)))\n",
    "#         def remove_hashtags_and_ats(x):\n",
    "#             return x.replace('#', '').replace('@', '')\n",
    "#         df['text'] = df['text'].apply(remove_hashtags_and_ats)\n",
    "#         if df.shape[0] != 0:\n",
    "#             print('user_id: {}'.format(user_id))\n",
    "#             print(text_clf.predict_proba(df['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet_id in data_cfg['tweet_ids']:\n",
    "    user_ids = list(tweets[tweet_id]['user_ids'].keys())\n",
    "    print('Tweet ID: {}'.format(tweet_id))\n",
    "    print(user_ids)\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = '1061497789'\n",
    "df = pd.read_csv(os.path.join(data_cfg['output_user_data_path'], 'user_{}_tweets.csv'.format(user_id)))\n",
    "def remove_hashtags_and_ats(x):\n",
    "    return x.replace('#', '').replace('@', '')\n",
    "df['text'] = df['text'].apply(remove_hashtags_and_ats)\n",
    "display(df['text'])\n",
    "if df.shape[0] != 0:\n",
    "    print('user_id: {}'.format(user_id))\n",
    "    print(text_clf.predict(df['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
