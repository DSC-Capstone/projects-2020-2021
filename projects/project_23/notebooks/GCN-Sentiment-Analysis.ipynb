{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GinNZkSBeFdC"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/data')\n",
    "from data_loader_sen import data_loader_sen\n",
    "sys.path.append('../src/models')\n",
    "from GCN_model import n_hidden_GCN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the result of using Sentiment Analysis of tweets of 116th senators as feature and graph of 116th senators as adjacency matrix to predict their political parties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "XR6h2vG9L7ls"
   },
   "outputs": [],
   "source": [
    "loader = data_loader_sen( \"../data/voting_features.csv\",\"../data/tweets.csv\", \"../data/edges.csv\")\n",
    "features, labels, A = loader.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Py0zsfIzL-VT",
    "outputId": "1e13d86a-1003-4b65-c945-eb0b41b63e95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train length :70, Validation length :30\n",
      "Epoch: 0\n",
      "training loss 6.0129\n",
      "Validtion: Average loss: 0.0000, Accuracy: 0.0000%\n",
      "Epoch: 1\n",
      "training loss 5.8542\n",
      "Validtion: Average loss: 0.0000, Accuracy: 0.0000%\n",
      "Epoch: 2\n",
      "training loss 5.6975\n",
      "Validtion: Average loss: 0.0000, Accuracy: 0.0000%\n",
      "Epoch: 3\n",
      "training loss 5.5440\n",
      "Validtion: Average loss: 0.0000, Accuracy: 0.0000%\n",
      "Epoch: 4\n",
      "training loss 5.3925\n",
      "Validtion: Average loss: 0.0000, Accuracy: 0.0000%\n",
      "Epoch: 5\n",
      "training loss 5.2434\n",
      "Validtion: Average loss: 0.0000, Accuracy: 0.0000%\n",
      "Epoch: 6\n",
      "training loss 5.0967\n",
      "Validtion: Average loss: 0.0000, Accuracy: 0.0000%\n",
      "Epoch: 7\n",
      "training loss 4.9528\n",
      "Validtion: Average loss: 0.0000, Accuracy: 0.0000%\n",
      "Epoch: 8\n",
      "training loss 4.8110\n",
      "Validtion: Average loss: 0.0000, Accuracy: 0.0000%\n",
      "Epoch: 9\n",
      "training loss 4.6685\n",
      "Validtion: Average loss: 0.0000, Accuracy: 0.0000%\n",
      "Epoch: 10\n",
      "training loss 4.5286\n",
      "Validtion: Average loss: 0.0000, Accuracy: 0.0000%\n",
      "Epoch: 11\n",
      "training loss 4.3909\n",
      "Validtion: Average loss: 0.0000, Accuracy: 3.3333%\n",
      "Epoch: 12\n",
      "training loss 4.2577\n",
      "Validtion: Average loss: 0.0000, Accuracy: 3.3333%\n",
      "Epoch: 13\n",
      "training loss 4.1289\n",
      "Validtion: Average loss: 0.0000, Accuracy: 3.3333%\n",
      "Epoch: 14\n",
      "training loss 4.0045\n",
      "Validtion: Average loss: 0.0000, Accuracy: 6.6667%\n",
      "Epoch: 15\n",
      "training loss 3.8861\n",
      "Validtion: Average loss: 0.0000, Accuracy: 6.6667%\n",
      "Epoch: 16\n",
      "training loss 3.7705\n",
      "Validtion: Average loss: 0.0000, Accuracy: 6.6667%\n",
      "Epoch: 17\n",
      "training loss 3.6600\n",
      "Validtion: Average loss: 0.0000, Accuracy: 10.0000%\n",
      "Epoch: 18\n",
      "training loss 3.5534\n",
      "Validtion: Average loss: 0.0000, Accuracy: 10.0000%\n",
      "Epoch: 19\n",
      "training loss 3.4513\n",
      "Validtion: Average loss: 0.0000, Accuracy: 10.0000%\n",
      "Epoch: 20\n",
      "training loss 3.3521\n",
      "Validtion: Average loss: 0.0000, Accuracy: 10.0000%\n",
      "Epoch: 21\n",
      "training loss 3.2514\n",
      "Validtion: Average loss: 0.0000, Accuracy: 10.0000%\n",
      "Epoch: 22\n",
      "training loss 3.1536\n",
      "Validtion: Average loss: 0.0000, Accuracy: 10.0000%\n",
      "Epoch: 23\n",
      "training loss 3.0595\n",
      "Validtion: Average loss: 0.0000, Accuracy: 10.0000%\n",
      "Epoch: 24\n",
      "training loss 2.9664\n",
      "Validtion: Average loss: 0.0000, Accuracy: 13.3333%\n",
      "Epoch: 25\n",
      "training loss 2.8765\n",
      "Validtion: Average loss: 0.0000, Accuracy: 13.3333%\n",
      "Epoch: 26\n",
      "training loss 2.7892\n",
      "Validtion: Average loss: 0.0000, Accuracy: 13.3333%\n",
      "Epoch: 27\n",
      "training loss 2.7045\n",
      "Validtion: Average loss: 0.0000, Accuracy: 13.3333%\n",
      "Epoch: 28\n",
      "training loss 2.6224\n",
      "Validtion: Average loss: 0.0000, Accuracy: 13.3333%\n",
      "Epoch: 29\n",
      "training loss 2.5439\n",
      "Validtion: Average loss: 0.0000, Accuracy: 13.3333%\n",
      "Epoch: 30\n",
      "training loss 2.4678\n",
      "Validtion: Average loss: 0.0000, Accuracy: 16.6667%\n",
      "Epoch: 31\n",
      "training loss 2.3926\n",
      "Validtion: Average loss: 0.0000, Accuracy: 23.3333%\n",
      "Epoch: 32\n",
      "training loss 2.3200\n",
      "Validtion: Average loss: 0.0000, Accuracy: 30.0000%\n",
      "Epoch: 33\n",
      "training loss 2.2504\n",
      "Validtion: Average loss: 0.0000, Accuracy: 30.0000%\n",
      "Epoch: 34\n",
      "training loss 2.1836\n",
      "Validtion: Average loss: 0.0000, Accuracy: 30.0000%\n",
      "Epoch: 35\n",
      "training loss 2.1139\n",
      "Validtion: Average loss: 0.0000, Accuracy: 33.3333%\n",
      "Epoch: 36\n",
      "training loss 2.0452\n",
      "Validtion: Average loss: 0.0000, Accuracy: 36.6667%\n",
      "Epoch: 37\n",
      "training loss 1.9735\n",
      "Validtion: Average loss: 0.0000, Accuracy: 36.6667%\n",
      "Epoch: 38\n",
      "training loss 1.8965\n",
      "Validtion: Average loss: 0.0000, Accuracy: 36.6667%\n",
      "Epoch: 39\n",
      "training loss 1.8156\n",
      "Validtion: Average loss: 0.0000, Accuracy: 36.6667%\n",
      "Epoch: 40\n",
      "training loss 1.7331\n",
      "Validtion: Average loss: 0.0000, Accuracy: 36.6667%\n",
      "Epoch: 41\n",
      "training loss 1.6521\n",
      "Validtion: Average loss: 0.0000, Accuracy: 36.6667%\n",
      "Epoch: 42\n",
      "training loss 1.5743\n",
      "Validtion: Average loss: 0.0000, Accuracy: 36.6667%\n",
      "Epoch: 43\n",
      "training loss 1.5008\n",
      "Validtion: Average loss: 0.0000, Accuracy: 36.6667%\n",
      "Epoch: 44\n",
      "training loss 1.4317\n",
      "Validtion: Average loss: 0.0000, Accuracy: 33.3333%\n",
      "Epoch: 45\n",
      "training loss 1.3674\n",
      "Validtion: Average loss: 0.0000, Accuracy: 33.3333%\n",
      "Epoch: 46\n",
      "training loss 1.3090\n",
      "Validtion: Average loss: 0.0000, Accuracy: 33.3333%\n",
      "Epoch: 47\n",
      "training loss 1.2569\n",
      "Validtion: Average loss: 0.0000, Accuracy: 36.6667%\n",
      "Epoch: 48\n",
      "training loss 1.2110\n",
      "Validtion: Average loss: 0.0000, Accuracy: 36.6667%\n",
      "Epoch: 49\n",
      "training loss 1.1710\n",
      "Validtion: Average loss: 0.0000, Accuracy: 36.6667%\n",
      "Epoch: 50\n",
      "training loss 1.1359\n",
      "Validtion: Average loss: 0.0000, Accuracy: 43.3333%\n",
      "Epoch: 51\n",
      "training loss 1.1050\n",
      "Validtion: Average loss: 0.0000, Accuracy: 46.6667%\n",
      "Epoch: 52\n",
      "training loss 1.0774\n",
      "Validtion: Average loss: 0.0000, Accuracy: 46.6667%\n",
      "Epoch: 53\n",
      "training loss 1.0526\n",
      "Validtion: Average loss: 0.0000, Accuracy: 46.6667%\n",
      "Epoch: 54\n",
      "training loss 1.0302\n",
      "Validtion: Average loss: 0.0000, Accuracy: 46.6667%\n",
      "Epoch: 55\n",
      "training loss 1.0097\n",
      "Validtion: Average loss: 0.0000, Accuracy: 50.0000%\n",
      "Epoch: 56\n",
      "training loss 0.9903\n",
      "Validtion: Average loss: 0.0000, Accuracy: 53.3333%\n",
      "Epoch: 57\n",
      "training loss 0.9708\n",
      "Validtion: Average loss: 0.0000, Accuracy: 50.0000%\n",
      "Epoch: 58\n",
      "training loss 0.9524\n",
      "Validtion: Average loss: 0.0000, Accuracy: 50.0000%\n",
      "Epoch: 59\n",
      "training loss 0.9349\n",
      "Validtion: Average loss: 0.0000, Accuracy: 50.0000%\n",
      "Epoch: 60\n",
      "training loss 0.9182\n",
      "Validtion: Average loss: 0.0000, Accuracy: 50.0000%\n",
      "Epoch: 61\n",
      "training loss 0.9022\n",
      "Validtion: Average loss: 0.0000, Accuracy: 50.0000%\n",
      "Epoch: 62\n",
      "training loss 0.8868\n",
      "Validtion: Average loss: 0.0000, Accuracy: 50.0000%\n",
      "Epoch: 63\n",
      "training loss 0.8721\n",
      "Validtion: Average loss: 0.0000, Accuracy: 53.3333%\n",
      "Epoch: 64\n",
      "training loss 0.8573\n",
      "Validtion: Average loss: 0.0000, Accuracy: 53.3333%\n",
      "Epoch: 65\n",
      "training loss 0.8428\n",
      "Validtion: Average loss: 0.0000, Accuracy: 53.3333%\n",
      "Epoch: 66\n",
      "training loss 0.8286\n",
      "Validtion: Average loss: 0.0000, Accuracy: 56.6667%\n",
      "Epoch: 67\n",
      "training loss 0.8149\n",
      "Validtion: Average loss: 0.0000, Accuracy: 56.6667%\n",
      "Epoch: 68\n",
      "training loss 0.8015\n",
      "Validtion: Average loss: 0.0000, Accuracy: 60.0000%\n",
      "Epoch: 69\n",
      "training loss 0.7885\n",
      "Validtion: Average loss: 0.0000, Accuracy: 60.0000%\n",
      "Epoch: 70\n",
      "training loss 0.7759\n",
      "Validtion: Average loss: 0.0000, Accuracy: 63.3333%\n",
      "Epoch: 71\n",
      "training loss 0.7636\n",
      "Validtion: Average loss: 0.0000, Accuracy: 63.3333%\n",
      "Epoch: 72\n",
      "training loss 0.7517\n",
      "Validtion: Average loss: 0.0000, Accuracy: 63.3333%\n",
      "Epoch: 73\n",
      "training loss 0.7403\n",
      "Validtion: Average loss: 0.0000, Accuracy: 63.3333%\n",
      "Epoch: 74\n",
      "training loss 0.7292\n",
      "Validtion: Average loss: 0.0000, Accuracy: 63.3333%\n",
      "Epoch: 75\n",
      "training loss 0.7184\n",
      "Validtion: Average loss: 0.0000, Accuracy: 63.3333%\n",
      "Epoch: 76\n",
      "training loss 0.7081\n",
      "Validtion: Average loss: 0.0000, Accuracy: 63.3333%\n",
      "Epoch: 77\n",
      "training loss 0.6981\n",
      "Validtion: Average loss: 0.0000, Accuracy: 63.3333%\n",
      "Epoch: 78\n",
      "training loss 0.6885\n",
      "Validtion: Average loss: 0.0000, Accuracy: 63.3333%\n",
      "Epoch: 79\n",
      "training loss 0.6792\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 80\n",
      "training loss 0.6703\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 81\n",
      "training loss 0.6616\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 82\n",
      "training loss 0.6532\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 83\n",
      "training loss 0.6450\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 84\n",
      "training loss 0.6370\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 85\n",
      "training loss 0.6292\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 86\n",
      "training loss 0.6215\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 87\n",
      "training loss 0.6141\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 88\n",
      "training loss 0.6068\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 89\n",
      "training loss 0.5997\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 90\n",
      "training loss 0.5928\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 91\n",
      "training loss 0.5860\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 92\n",
      "training loss 0.5794\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 93\n",
      "training loss 0.5730\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 94\n",
      "training loss 0.5667\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 95\n",
      "training loss 0.5605\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 96\n",
      "training loss 0.5544\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 97\n",
      "training loss 0.5484\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 98\n",
      "training loss 0.5425\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 99\n",
      "training loss 0.5368\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 100\n",
      "training loss 0.5311\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 101\n",
      "training loss 0.5255\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 102\n",
      "training loss 0.5200\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 103\n",
      "training loss 0.5146\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 104\n",
      "training loss 0.5092\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 105\n",
      "training loss 0.5040\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 106\n",
      "training loss 0.4988\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 107\n",
      "training loss 0.4937\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 108\n",
      "training loss 0.4887\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 109\n",
      "training loss 0.4837\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 110\n",
      "training loss 0.4789\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 111\n",
      "training loss 0.4741\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 112\n",
      "training loss 0.4694\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 113\n",
      "training loss 0.4648\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 114\n",
      "training loss 0.4602\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 115\n",
      "training loss 0.4558\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 116\n",
      "training loss 0.4515\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 117\n",
      "training loss 0.4473\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 118\n",
      "training loss 0.4432\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 119\n",
      "training loss 0.4392\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 120\n",
      "training loss 0.4352\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 121\n",
      "training loss 0.4313\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 122\n",
      "training loss 0.4275\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 123\n",
      "training loss 0.4237\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 124\n",
      "training loss 0.4200\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 125\n",
      "training loss 0.4163\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 126\n",
      "training loss 0.4127\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 127\n",
      "training loss 0.4092\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 128\n",
      "training loss 0.4057\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 129\n",
      "training loss 0.4023\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 130\n",
      "training loss 0.3989\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 131\n",
      "training loss 0.3955\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 132\n",
      "training loss 0.3922\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 133\n",
      "training loss 0.3890\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 134\n",
      "training loss 0.3858\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 135\n",
      "training loss 0.3827\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 136\n",
      "training loss 0.3797\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 137\n",
      "training loss 0.3767\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 138\n",
      "training loss 0.3738\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 139\n",
      "training loss 0.3709\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 140\n",
      "training loss 0.3680\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 141\n",
      "training loss 0.3652\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 142\n",
      "training loss 0.3624\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 143\n",
      "training loss 0.3596\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 144\n",
      "training loss 0.3569\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 145\n",
      "training loss 0.3543\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 146\n",
      "training loss 0.3517\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 147\n",
      "training loss 0.3491\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 148\n",
      "training loss 0.3465\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 149\n",
      "training loss 0.3440\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 150\n",
      "training loss 0.3416\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 151\n",
      "training loss 0.3391\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 152\n",
      "training loss 0.3367\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 153\n",
      "training loss 0.3344\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 154\n",
      "training loss 0.3320\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 155\n",
      "training loss 0.3297\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 156\n",
      "training loss 0.3274\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 157\n",
      "training loss 0.3252\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 158\n",
      "training loss 0.3230\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 159\n",
      "training loss 0.3208\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 160\n",
      "training loss 0.3187\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 161\n",
      "training loss 0.3166\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 162\n",
      "training loss 0.3145\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 163\n",
      "training loss 0.3125\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 164\n",
      "training loss 0.3104\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 165\n",
      "training loss 0.3084\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 166\n",
      "training loss 0.3064\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 167\n",
      "training loss 0.3045\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 168\n",
      "training loss 0.3025\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 169\n",
      "training loss 0.3007\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 170\n",
      "training loss 0.2988\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 171\n",
      "training loss 0.2969\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 172\n",
      "training loss 0.2951\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 173\n",
      "training loss 0.2933\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 174\n",
      "training loss 0.2916\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 175\n",
      "training loss 0.2899\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 176\n",
      "training loss 0.2881\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 177\n",
      "training loss 0.2864\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 178\n",
      "training loss 0.2848\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 179\n",
      "training loss 0.2831\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 180\n",
      "training loss 0.2814\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 181\n",
      "training loss 0.2798\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 182\n",
      "training loss 0.2782\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 183\n",
      "training loss 0.2766\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 184\n",
      "training loss 0.2750\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 185\n",
      "training loss 0.2734\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 186\n",
      "training loss 0.2718\n",
      "Validtion: Average loss: 0.0000, Accuracy: 70.0000%\n",
      "Epoch: 187\n",
      "training loss 0.2703\n",
      "Validtion: Average loss: 0.0000, Accuracy: 70.0000%\n",
      "Epoch: 188\n",
      "training loss 0.2687\n",
      "Validtion: Average loss: 0.0000, Accuracy: 70.0000%\n",
      "Epoch: 189\n",
      "training loss 0.2671\n",
      "Validtion: Average loss: 0.0000, Accuracy: 70.0000%\n",
      "Epoch: 190\n",
      "training loss 0.2656\n",
      "Validtion: Average loss: 0.0000, Accuracy: 70.0000%\n",
      "Epoch: 191\n",
      "training loss 0.2641\n",
      "Validtion: Average loss: 0.0000, Accuracy: 70.0000%\n",
      "Epoch: 192\n",
      "training loss 0.2626\n",
      "Validtion: Average loss: 0.0000, Accuracy: 70.0000%\n",
      "Epoch: 193\n",
      "training loss 0.2611\n",
      "Validtion: Average loss: 0.0000, Accuracy: 70.0000%\n",
      "Epoch: 194\n",
      "training loss 0.2596\n",
      "Validtion: Average loss: 0.0000, Accuracy: 70.0000%\n",
      "Epoch: 195\n",
      "training loss 0.2581\n",
      "Validtion: Average loss: 0.0000, Accuracy: 70.0000%\n",
      "Epoch: 196\n",
      "training loss 0.2567\n",
      "Validtion: Average loss: 0.0000, Accuracy: 70.0000%\n",
      "Epoch: 197\n",
      "training loss 0.2553\n",
      "Validtion: Average loss: 0.0000, Accuracy: 70.0000%\n",
      "Epoch: 198\n",
      "training loss 0.2539\n",
      "Validtion: Average loss: 0.0000, Accuracy: 70.0000%\n",
      "Epoch: 199\n",
      "training loss 0.2525\n",
      "Validtion: Average loss: 0.0000, Accuracy: 70.0000%\n",
      "Epoch: 200\n",
      "training loss 0.2511\n",
      "Validtion: Average loss: 0.0000, Accuracy: 70.0000%\n",
      "Epoch: 201\n",
      "training loss 0.2497\n",
      "Validtion: Average loss: 0.0000, Accuracy: 70.0000%\n",
      "Epoch: 202\n",
      "training loss 0.2484\n",
      "Validtion: Average loss: 0.0000, Accuracy: 70.0000%\n",
      "Epoch: 203\n",
      "training loss 0.2470\n",
      "Validtion: Average loss: 0.0000, Accuracy: 70.0000%\n",
      "Epoch: 204\n",
      "training loss 0.2457\n",
      "Validtion: Average loss: 0.0000, Accuracy: 70.0000%\n",
      "Epoch: 205\n",
      "training loss 0.2444\n",
      "Validtion: Average loss: 0.0000, Accuracy: 70.0000%\n",
      "Epoch: 206\n",
      "training loss 0.2430\n",
      "Validtion: Average loss: 0.0000, Accuracy: 70.0000%\n",
      "Epoch: 207\n",
      "training loss 0.2417\n",
      "Validtion: Average loss: 0.0000, Accuracy: 70.0000%\n",
      "Epoch: 208\n",
      "training loss 0.2404\n",
      "Validtion: Average loss: 0.0000, Accuracy: 73.3333%\n",
      "Epoch: 209\n",
      "training loss 0.2391\n",
      "Validtion: Average loss: 0.0000, Accuracy: 73.3333%\n",
      "Epoch: 210\n",
      "training loss 0.2379\n",
      "Validtion: Average loss: 0.0000, Accuracy: 73.3333%\n",
      "Epoch: 211\n",
      "training loss 0.2367\n",
      "Validtion: Average loss: 0.0000, Accuracy: 73.3333%\n",
      "Epoch: 212\n",
      "training loss 0.2354\n",
      "Validtion: Average loss: 0.0000, Accuracy: 73.3333%\n",
      "Epoch: 213\n",
      "training loss 0.2342\n",
      "Validtion: Average loss: 0.0000, Accuracy: 73.3333%\n",
      "Epoch: 214\n",
      "training loss 0.2330\n",
      "Validtion: Average loss: 0.0000, Accuracy: 73.3333%\n",
      "Epoch: 215\n",
      "training loss 0.2318\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 216\n",
      "training loss 0.2306\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 217\n",
      "training loss 0.2295\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 218\n",
      "training loss 0.2283\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 219\n",
      "training loss 0.2272\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 220\n",
      "training loss 0.2260\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 221\n",
      "training loss 0.2249\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 222\n",
      "training loss 0.2238\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 223\n",
      "training loss 0.2227\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 224\n",
      "training loss 0.2216\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 225\n",
      "training loss 0.2205\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 226\n",
      "training loss 0.2194\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 227\n",
      "training loss 0.2184\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 228\n",
      "training loss 0.2173\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 229\n",
      "training loss 0.2163\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 230\n",
      "training loss 0.2152\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 231\n",
      "training loss 0.2142\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 232\n",
      "training loss 0.2132\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 233\n",
      "training loss 0.2121\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 234\n",
      "training loss 0.2111\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 235\n",
      "training loss 0.2101\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 236\n",
      "training loss 0.2091\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 237\n",
      "training loss 0.2081\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 238\n",
      "training loss 0.2072\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 239\n",
      "training loss 0.2062\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 240\n",
      "training loss 0.2052\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 241\n",
      "training loss 0.2042\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 242\n",
      "training loss 0.2033\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 243\n",
      "training loss 0.2023\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 244\n",
      "training loss 0.2014\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 245\n",
      "training loss 0.2004\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 246\n",
      "training loss 0.1995\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 247\n",
      "training loss 0.1986\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 248\n",
      "training loss 0.1977\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 249\n",
      "training loss 0.1967\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 250\n",
      "training loss 0.1958\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 251\n",
      "training loss 0.1950\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 252\n",
      "training loss 0.1941\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 253\n",
      "training loss 0.1932\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 254\n",
      "training loss 0.1923\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 255\n",
      "training loss 0.1914\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 256\n",
      "training loss 0.1906\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 257\n",
      "training loss 0.1897\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 258\n",
      "training loss 0.1889\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 259\n",
      "training loss 0.1880\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 260\n",
      "training loss 0.1872\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 261\n",
      "training loss 0.1863\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 262\n",
      "training loss 0.1855\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 263\n",
      "training loss 0.1847\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 264\n",
      "training loss 0.1839\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 265\n",
      "training loss 0.1830\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 266\n",
      "training loss 0.1822\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 267\n",
      "training loss 0.1814\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 268\n",
      "training loss 0.1806\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 269\n",
      "training loss 0.1799\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 270\n",
      "training loss 0.1791\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 271\n",
      "training loss 0.1783\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 272\n",
      "training loss 0.1775\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 273\n",
      "training loss 0.1767\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 274\n",
      "training loss 0.1759\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 275\n",
      "training loss 0.1751\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 276\n",
      "training loss 0.1743\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 277\n",
      "training loss 0.1735\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 278\n",
      "training loss 0.1727\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 279\n",
      "training loss 0.1720\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 280\n",
      "training loss 0.1712\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 281\n",
      "training loss 0.1705\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 282\n",
      "training loss 0.1697\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 283\n",
      "training loss 0.1689\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 284\n",
      "training loss 0.1682\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 285\n",
      "training loss 0.1675\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 286\n",
      "training loss 0.1667\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 287\n",
      "training loss 0.1660\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 288\n",
      "training loss 0.1653\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 289\n",
      "training loss 0.1646\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 290\n",
      "training loss 0.1639\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 291\n",
      "training loss 0.1632\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 292\n",
      "training loss 0.1625\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 293\n",
      "training loss 0.1618\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 294\n",
      "training loss 0.1611\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 295\n",
      "training loss 0.1604\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 296\n",
      "training loss 0.1598\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 297\n",
      "training loss 0.1591\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 298\n",
      "training loss 0.1585\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 299\n",
      "training loss 0.1578\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 300\n",
      "training loss 0.1572\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 301\n",
      "training loss 0.1566\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 302\n",
      "training loss 0.1559\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 303\n",
      "training loss 0.1553\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 304\n",
      "training loss 0.1547\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 305\n",
      "training loss 0.1541\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 306\n",
      "training loss 0.1535\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 307\n",
      "training loss 0.1529\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 308\n",
      "training loss 0.1523\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 309\n",
      "training loss 0.1517\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 310\n",
      "training loss 0.1511\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 311\n",
      "training loss 0.1505\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 312\n",
      "training loss 0.1500\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 313\n",
      "training loss 0.1494\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 314\n",
      "training loss 0.1488\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 315\n",
      "training loss 0.1482\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 316\n",
      "training loss 0.1477\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 317\n",
      "training loss 0.1471\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 318\n",
      "training loss 0.1466\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 319\n",
      "training loss 0.1460\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 320\n",
      "training loss 0.1455\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 321\n",
      "training loss 0.1449\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 322\n",
      "training loss 0.1444\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 323\n",
      "training loss 0.1438\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 324\n",
      "training loss 0.1433\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 325\n",
      "training loss 0.1428\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 326\n",
      "training loss 0.1422\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 327\n",
      "training loss 0.1417\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 328\n",
      "training loss 0.1412\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 329\n",
      "training loss 0.1407\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 330\n",
      "training loss 0.1402\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 331\n",
      "training loss 0.1396\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 332\n",
      "training loss 0.1391\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 333\n",
      "training loss 0.1387\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 334\n",
      "training loss 0.1382\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 335\n",
      "training loss 0.1377\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 336\n",
      "training loss 0.1372\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 337\n",
      "training loss 0.1367\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 338\n",
      "training loss 0.1362\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 339\n",
      "training loss 0.1358\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 340\n",
      "training loss 0.1353\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 341\n",
      "training loss 0.1348\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 342\n",
      "training loss 0.1343\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 343\n",
      "training loss 0.1339\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 344\n",
      "training loss 0.1334\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 345\n",
      "training loss 0.1329\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 346\n",
      "training loss 0.1324\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 347\n",
      "training loss 0.1320\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 348\n",
      "training loss 0.1315\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 349\n",
      "training loss 0.1311\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 350\n",
      "training loss 0.1306\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 351\n",
      "training loss 0.1302\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 352\n",
      "training loss 0.1297\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 353\n",
      "training loss 0.1293\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 354\n",
      "training loss 0.1289\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 355\n",
      "training loss 0.1284\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 356\n",
      "training loss 0.1280\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 357\n",
      "training loss 0.1276\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 358\n",
      "training loss 0.1271\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 359\n",
      "training loss 0.1267\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 360\n",
      "training loss 0.1263\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 361\n",
      "training loss 0.1259\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 362\n",
      "training loss 0.1255\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 363\n",
      "training loss 0.1250\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 364\n",
      "training loss 0.1246\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 365\n",
      "training loss 0.1242\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 366\n",
      "training loss 0.1238\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 367\n",
      "training loss 0.1234\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 368\n",
      "training loss 0.1229\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 369\n",
      "training loss 0.1225\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 370\n",
      "training loss 0.1221\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 371\n",
      "training loss 0.1217\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 372\n",
      "training loss 0.1213\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 373\n",
      "training loss 0.1209\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 374\n",
      "training loss 0.1205\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 375\n",
      "training loss 0.1201\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 376\n",
      "training loss 0.1197\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 377\n",
      "training loss 0.1193\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 378\n",
      "training loss 0.1189\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 379\n",
      "training loss 0.1185\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 380\n",
      "training loss 0.1181\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 381\n",
      "training loss 0.1177\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 382\n",
      "training loss 0.1174\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 383\n",
      "training loss 0.1170\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 384\n",
      "training loss 0.1167\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 385\n",
      "training loss 0.1163\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 386\n",
      "training loss 0.1159\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 387\n",
      "training loss 0.1156\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 388\n",
      "training loss 0.1152\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 389\n",
      "training loss 0.1149\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 390\n",
      "training loss 0.1145\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 391\n",
      "training loss 0.1142\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 392\n",
      "training loss 0.1138\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 393\n",
      "training loss 0.1135\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 394\n",
      "training loss 0.1131\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 395\n",
      "training loss 0.1128\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 396\n",
      "training loss 0.1125\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 397\n",
      "training loss 0.1121\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 398\n",
      "training loss 0.1118\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 399\n",
      "training loss 0.1115\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  3.3333333333333335,\n",
       "  3.3333333333333335,\n",
       "  3.3333333333333335,\n",
       "  6.666666666666667,\n",
       "  6.666666666666667,\n",
       "  6.666666666666667,\n",
       "  10.0,\n",
       "  10.0,\n",
       "  10.0,\n",
       "  10.0,\n",
       "  10.0,\n",
       "  10.0,\n",
       "  10.0,\n",
       "  13.333333333333334,\n",
       "  13.333333333333334,\n",
       "  13.333333333333334,\n",
       "  13.333333333333334,\n",
       "  13.333333333333334,\n",
       "  13.333333333333334,\n",
       "  16.666666666666668,\n",
       "  23.333333333333332,\n",
       "  30.0,\n",
       "  30.0,\n",
       "  30.0,\n",
       "  33.333333333333336,\n",
       "  36.666666666666664,\n",
       "  36.666666666666664,\n",
       "  36.666666666666664,\n",
       "  36.666666666666664,\n",
       "  36.666666666666664,\n",
       "  36.666666666666664,\n",
       "  36.666666666666664,\n",
       "  36.666666666666664,\n",
       "  33.333333333333336,\n",
       "  33.333333333333336,\n",
       "  33.333333333333336,\n",
       "  36.666666666666664,\n",
       "  36.666666666666664,\n",
       "  36.666666666666664,\n",
       "  43.333333333333336,\n",
       "  46.666666666666664,\n",
       "  46.666666666666664,\n",
       "  46.666666666666664,\n",
       "  46.666666666666664,\n",
       "  50.0,\n",
       "  53.333333333333336,\n",
       "  50.0,\n",
       "  50.0,\n",
       "  50.0,\n",
       "  50.0,\n",
       "  50.0,\n",
       "  50.0,\n",
       "  53.333333333333336,\n",
       "  53.333333333333336,\n",
       "  53.333333333333336,\n",
       "  56.666666666666664,\n",
       "  56.666666666666664,\n",
       "  60.0,\n",
       "  60.0,\n",
       "  63.333333333333336,\n",
       "  63.333333333333336,\n",
       "  63.333333333333336,\n",
       "  63.333333333333336,\n",
       "  63.333333333333336,\n",
       "  63.333333333333336,\n",
       "  63.333333333333336,\n",
       "  63.333333333333336,\n",
       "  63.333333333333336,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  70.0,\n",
       "  70.0,\n",
       "  70.0,\n",
       "  70.0,\n",
       "  70.0,\n",
       "  70.0,\n",
       "  70.0,\n",
       "  70.0,\n",
       "  70.0,\n",
       "  70.0,\n",
       "  70.0,\n",
       "  70.0,\n",
       "  70.0,\n",
       "  70.0,\n",
       "  70.0,\n",
       "  70.0,\n",
       "  70.0,\n",
       "  70.0,\n",
       "  70.0,\n",
       "  70.0,\n",
       "  70.0,\n",
       "  70.0,\n",
       "  73.33333333333333,\n",
       "  73.33333333333333,\n",
       "  73.33333333333333,\n",
       "  73.33333333333333,\n",
       "  73.33333333333333,\n",
       "  73.33333333333333,\n",
       "  73.33333333333333,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  76.66666666666667,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333]}"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = n_hidden_GCN(A, features, labels, hidden_neurons=100, F = 1000, val_size=0.3)\n",
    "model.train_epoch(epochs=400, lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V9cpRMDmLfAh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "GCN.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
