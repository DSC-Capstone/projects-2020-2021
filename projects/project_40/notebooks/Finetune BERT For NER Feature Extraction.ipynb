{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import json\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=os.getcwd()+'\\\\BERT-NER'\n",
    "notebook_path=os.getcwd()\n",
    "data_path=os.getcwd()[:-9]+'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: could not create work tree dir 'os.getcwd()[:-9]': Invalid argument\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/kamalkraj/BERT-NER.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_ner.py --data_dir=data/ --bert_model=bert-base-cased --task_name=ner --output_dir=out_ner --max_seq_length=128 --do_train --num_train_epochs 3 --do_eval --warmup_proportion=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download the BERT model and finetune it on Conll2003.\n",
    "\n",
    "%%writefile bert.py\n",
    "\"\"\"BERT NER Inference.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from nltk import word_tokenize\n",
    "from pytorch_transformers import (BertConfig, BertForTokenClassification,\n",
    "                                  BertTokenizer)\n",
    "\n",
    "\n",
    "class BertNer(BertForTokenClassification):\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, valid_ids=None):\n",
    "        sequence_output = self.bert(input_ids, token_type_ids, attention_mask, head_mask=None)[0]\n",
    "        batch_size,max_len,feat_dim = sequence_output.shape\n",
    "        valid_output = torch.zeros(batch_size,max_len,feat_dim,dtype=torch.float32,device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        for i in range(batch_size):\n",
    "            jj = -1\n",
    "            for j in range(max_len):\n",
    "                    if valid_ids[i][j].item() == 1:\n",
    "                        jj += 1\n",
    "                        valid_output[i][jj] = sequence_output[i][j]\n",
    "        sequence_output = self.dropout(valid_output)\n",
    "        logits = self.classifier(sequence_output)\n",
    "        return logits\n",
    "\n",
    "class Ner:\n",
    "\n",
    "    def __init__(self,model_dir: str):\n",
    "        self.model , self.tokenizer, self.model_config = self.load_model(model_dir)\n",
    "        self.label_map = self.model_config[\"label_map\"]\n",
    "        self.max_seq_length = self.model_config[\"max_seq_length\"]\n",
    "        self.label_map = {int(k):v for k,v in self.label_map.items()}\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "    def load_model(self, model_dir: str, model_config: str = \"model_config.json\"):\n",
    "        model_config = os.path.join(model_dir,model_config)\n",
    "        model_config = json.load(open(model_config))\n",
    "        model = BertNer.from_pretrained(model_dir)\n",
    "        tokenizer = BertTokenizer.from_pretrained(model_dir, do_lower_case=model_config[\"do_lower\"])\n",
    "        return model, tokenizer, model_config\n",
    "\n",
    "    def tokenize(self, text: str):\n",
    "        \"\"\" tokenize input\"\"\"\n",
    "        words = word_tokenize(text)\n",
    "        tokens = []\n",
    "        valid_positions = []\n",
    "        for i,word in enumerate(words):\n",
    "            token = self.tokenizer.tokenize(word)\n",
    "            tokens.extend(token)\n",
    "            for i in range(len(token)):\n",
    "                if i == 0:\n",
    "                    valid_positions.append(1)\n",
    "                else:\n",
    "                    valid_positions.append(0)\n",
    "        return tokens, valid_positions\n",
    "\n",
    "    def preprocess(self, text: str):\n",
    "        \"\"\" preprocess \"\"\"\n",
    "        tokens, valid_positions = self.tokenize(text)\n",
    "        ## insert \"[CLS]\"\n",
    "        tokens.insert(0,\"[CLS]\")\n",
    "        valid_positions.insert(0,1)\n",
    "        ## insert \"[SEP]\"\n",
    "        tokens.append(\"[SEP]\")\n",
    "        valid_positions.append(1)\n",
    "        segment_ids = []\n",
    "        for i in range(len(tokens)):\n",
    "            segment_ids.append(0)\n",
    "        input_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
    "        input_mask = [1] * len(input_ids)\n",
    "        while len(input_ids) < self.max_seq_length:\n",
    "            input_ids.append(0)\n",
    "            input_mask.append(0)\n",
    "            segment_ids.append(0)\n",
    "            valid_positions.append(0)\n",
    "        return input_ids,input_mask,segment_ids,valid_positions\n",
    "\n",
    "    def predict(self, text: str):\n",
    "        input_ids,input_mask,segment_ids,valid_ids = self.preprocess(text)\n",
    "        input_ids = torch.tensor([input_ids],dtype=torch.long,device=self.device)\n",
    "        input_mask = torch.tensor([input_mask],dtype=torch.long,device=self.device)\n",
    "        segment_ids = torch.tensor([segment_ids],dtype=torch.long,device=self.device)\n",
    "        valid_ids = torch.tensor([valid_ids],dtype=torch.long,device=self.device)\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(input_ids, segment_ids, input_mask,valid_ids)\n",
    "        logits = F.softmax(logits,dim=2)\n",
    "        logits_label = torch.argmax(logits,dim=2)\n",
    "        logits_label = logits_label.detach().cpu().numpy().tolist()[0]\n",
    "\n",
    "        logits_confidence = [values[label].item() for values,label in zip(logits[0],logits_label)]\n",
    "\n",
    "        logits = []\n",
    "        pos = 0\n",
    "        for index,mask in enumerate(valid_ids[0]):\n",
    "            if index == 0:\n",
    "                continue\n",
    "            if mask == 1:\n",
    "                logits.append((logits_label[index-pos],logits_confidence[index-pos]))\n",
    "            else:\n",
    "                pos += 1\n",
    "        logits.pop()\n",
    "\n",
    "        labels = [(self.label_map[label],confidence) for label,confidence in logits]\n",
    "        words = word_tokenize(text)\n",
    "        assert len(labels) == len(words)\n",
    "\n",
    "        Person = []\n",
    "        Location = []\n",
    "        Organization = []\n",
    "        Miscelleneous = []\n",
    "\n",
    "        for word, (label, confidence) in zip(words, labels):\n",
    "            if label==\"B-PER\" or label==\"I-PER\":\n",
    "                Person.append(word)\n",
    "            elif label==\"B-LOC\" or label==\"I-LOC\":\n",
    "                Location.append(word)\n",
    "            elif label==\"B-ORG\" or label==\"I-ORG\":\n",
    "                Organization.append(word)\n",
    "            elif label==\"B-MISC\" or label==\"I-MISC\":\n",
    "                Miscelleneous.append(word)\n",
    "            else:\n",
    "                output = None\n",
    "\n",
    "        output = []\n",
    "        for word, (label, confidence) in zip(words, labels):      \n",
    "            if label == \"B-PER\":\n",
    "                output.append(' '.join(Person) + \": Person\")\n",
    "            if label==\"B-LOC\":\n",
    "                output.append(' '.join(Location) + \": Location\")\n",
    "            if label==\"B-MISC\":\n",
    "                output.append(' '.join(Miscelleneous) + \": Miscelleneous Entity\")\n",
    "            if label==\"B-ORG\":\n",
    "                output.append(' '.join(Organization) + \": Organization\")\n",
    "                \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert import Ner\n",
    "model = Ner(\"out_ner/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(data_path)\n",
    "tf=pd.read_csv('summary_sentences.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_NE(values,model):\n",
    "    '''\n",
    "    Predict the NE results from values using model\n",
    "    '''\n",
    "    ne=[]\n",
    "    for sentence in values:\n",
    "        ne.append(model.predict(sentence))\n",
    "    return ne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 NEWS GROUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ne=predict_NE(tf.summary_sentences.values,model)\n",
    "tf['NE']=ne\n",
    "\n",
    "for i in ne: \n",
    "    for j in range(len(i)):\n",
    "        i[j]=i[j].split(':')[0]\n",
    "\n",
    "#Save to local csv\n",
    "tf.to_csv('Summary_Sentences_NE.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20 NEWS GROUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "news_df = pd.DataFrame.from_dict(newsgroups_train,'index').T\n",
    "news_df.data = news_df.data.apply(lambda x: clean_text(x)+ '.')\n",
    "news_df=news_df.reset_index()\n",
    "news_df['summary_sentences']=news_df.data.apply(lambda x:split_into_sentences(x))\n",
    "df_summary_sentences=news_df.summary_sentences.explode().reset_index()\n",
    "df_summary_sentences=df_summary_sentences.merge(news_df[['index','target']], on=\"index\", how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_largeNE(values,model):\n",
    "    ne2=[]\n",
    "    for sentence in values:\n",
    "        try:\n",
    "            if len(sentence)<512:\n",
    "                ne2.append(model.predict(sentence))\n",
    "            else:\n",
    "                ne2.append([])\n",
    "        except (AssertionError,TypeError):\n",
    "            ne2.append([])\n",
    "    return ne2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ne2=predict_largeNE(df_summary_sentences.summary_sentences.values,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary_sentences['NE']=ne2\n",
    "df_summary_sentences.to_csv('raw.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
