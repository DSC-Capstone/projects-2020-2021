{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint: Yelp Restaurant Reviews Sentiment and TF-IDF Result\n",
    "Let's analyze the sentiment for Yelp reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import Image\n",
    "from IPython.display import display_html\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../reference/dataframe/restaurant.csv', index_col=0)\n",
    "positive_phrases = pd.read_csv('../reference/dataframe/positive.csv', header=0, names=['phrases', 'count'])\n",
    "negative_phrases = pd.read_csv('../reference/dataframe/negative.csv', header=0, names=['phrases', 'count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the most positive phrases?\n",
    "Here are the most positive phrases in the given txt file, ranked by frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_phrases[0:10].plot.barh(title='Top 10 Positive Phrases', x='phrases').invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the most negative phrases?\n",
    "Here are the most negative phrases in the given txt file, ranked by freqency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_phrases[0:10].plot.barh(title='Top 10 Negative Phrases', x='phrases').invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(tokens=df.sentence.str.split(' '))\n",
    "df = df.assign(tokens=df.tokens.apply(lambda x: len(x)))\n",
    "df_rev = df.groupby('index')[['compound', 'tokens']].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the distribution of sentiment for these reviews?\n",
    "Looking at the distribution of how extreme the sentiment are for these reviews in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_rev.compound)\n",
    "plt.title(label='Distribution of Sentiment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the distribution of review length?\n",
    "Review length is the number of words written for a review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_rev.tokens)\n",
    "plt.title(label='Distribution of Review Length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the relationship between how positive/negative a review was and how long it was."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=df_rev['tokens'], y=df_rev['compound'])\n",
    "plt.title(\"Scatterplot of Sentiment vs. Review Length\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA of User Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The user distribution of our test dataframe\n",
    "- It is easy to observe that in the test data, individual user does not contain many reviews and most user contain only 1 review record.\n",
    "- We then explore the effect of the number of reviews on our AutoPhrase analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='../reference/img/most_20_user.png', width = 1000, height = 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AutoPhrase result for three users in our test review set\n",
    "- we choose two users that has a record of most reviews, second most reviews and one random user from the test data.\n",
    "- from the AutoPhrase result, we can observe that the user with more reviews preserve a more significant phrase than the users with less reviews.\n",
    "- then, we decide to filter out those users with less than 5 reivews in our later tf-idf analysis to ensure the quality of our recommendation result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_side_by_side(*args):\n",
    "    html_str=''\n",
    "    for i in args:\n",
    "        for df in i:\n",
    "            html_str+=df.to_html()\n",
    "    display_html(html_str.replace('table','table style=\"display:inline\"'),raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "for filename in os.listdir('../reference/AutoPhrase_result'):\n",
    "    path = '../reference/AutoPhrase_result/' + filename\n",
    "    if os.stat(path).st_size != 0:\n",
    "        df.append(pd.read_fwf(path, header = None, engine='python').rename(columns={0:'score',1:'phrase'}))\n",
    "display_side_by_side(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TD-IDF Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following two dataframes represent the target user we query for the recommendation and the recommendation user list we genreated.\n",
    "- we can observe that there does exist significant similarity between the recommended user and target user.\n",
    "- It will most likely to pop up the users who have been to the same restaurant and giev a similar review just like the target user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_index_df = pd.read_csv('../reference/dataframe/user_index.csv').drop(columns = ['Unnamed: 0'])\n",
    "user_recommendation_df = pd.read_csv('../reference/dataframe/user_recommendation.csv').drop(columns = ['Unnamed: 0'])\n",
    "display_side_by_side([user_index_df, user_recommendation_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following two dataframes represent the target restaurant we query for the recommendation and the recommendation restaurant list we genreated.\n",
    "- we can observe that there does exist significant similarity between the recommended restaurant and target restaurant.\n",
    "- It will most likely to pop up the restaurant who have a similar cateogories.\n",
    "- Also, the users review on the target restaurant will be considered as importance evalution features while make teh recommendation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_index_df = pd.read_csv('../reference/dataframe/rest_index.csv').drop(columns = ['Unnamed: 0'])\n",
    "rest_recommendation_df = pd.read_csv('../reference/dataframe/restaurant_recommendation.csv').drop(columns = ['Unnamed: 0'])\n",
    "display_side_by_side([rest_index_df, rest_recommendation_df])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
