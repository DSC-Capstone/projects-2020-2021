{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dgl\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLens(object):\n",
    "    def __init__(self, directory):\n",
    "        '''\n",
    "        directory: path to movielens directory which should have the three\n",
    "                   files:\n",
    "                   users.dat\n",
    "                   movies.dat\n",
    "                   ratings.dat\n",
    "        '''\n",
    "        self.directory = directory\n",
    "\n",
    "        users = []\n",
    "        movies = []\n",
    "        ratings = []\n",
    "\n",
    "        # read users\n",
    "        with open(os.path.join(directory, 'users.dat')) as f:\n",
    "            for l in f:\n",
    "                id_, gender, age, occupation, zip_ = l.split('::')\n",
    "                users.append({\n",
    "                    'id': int(id_),\n",
    "                    'gender': gender,\n",
    "                    'age': age,\n",
    "                    'occupation': occupation,\n",
    "                    'zip': zip_,\n",
    "                    })\n",
    "        self.users = pd.DataFrame(users).set_index('id')\n",
    "\n",
    "        # read movies\n",
    "        with open(os.path.join(directory, 'movies.dat'), encoding='latin1') as f:\n",
    "            for l in f:\n",
    "                id_, title, genres = l.split('::')\n",
    "                genres_set = set(genres.split('|'))\n",
    "                data = {'id': int(id_), 'title': title}\n",
    "                for g in genres_set:\n",
    "                    data[g] = True\n",
    "                movies.append(data)\n",
    "        self.movies = pd.DataFrame(movies).set_index('id')\n",
    "\n",
    "        # read ratings\n",
    "        with open(os.path.join(directory, 'ratings.dat')) as f:\n",
    "            for l in f:\n",
    "                user_id, movie_id, rating, timestamp = [int(_) for _ in l.split('::')]\n",
    "                ratings.append({\n",
    "                    'user_id': user_id,\n",
    "                    'movie_id': movie_id,\n",
    "                    'rating': rating,\n",
    "                    'timestamp': timestamp,\n",
    "                    })\n",
    "        self.ratings = pd.DataFrame(ratings)\n",
    "\n",
    "        # randomly generate training-validation-test set on the ratings table\n",
    "        test_set = self.ratings.sample(frac=0.05, random_state=1).index\n",
    "        valid_set = self.ratings.sample(frac=0.05, random_state=2).index\n",
    "        valid_set = valid_set.difference(test_set)\n",
    "        self.ratings['valid'] = self.ratings.index.isin(valid_set)\n",
    "        self.ratings['test'] = self.ratings.index.isin(test_set)\n",
    "\n",
    "    def todglgraph(self):\n",
    "        '''\n",
    "        returns:\n",
    "        g, user_ids, movie_ids:\n",
    "            The DGL graph itself.  Each edge has a binary feature \"valid\" and a binary\n",
    "            feature \"test\" indicating validation/test example.\n",
    "            The list of user IDs (node i corresponds to user user_ids[i])\n",
    "            The list of movie IDs (node i + len(user_ids) corresponds to movie movie_ids[i])\n",
    "        '''\n",
    "        user_ids = list(self.users.index)\n",
    "        movie_ids = list(self.movies.index)\n",
    "\n",
    "        user_ids_invmap = {id_: i for i, id_ in enumerate(user_ids)}\n",
    "        movie_ids_invmap = {id_: i for i, id_ in enumerate(movie_ids)}\n",
    "\n",
    "        g = dgl.DGLGraph()\n",
    "        g.add_nodes(len(user_ids) + len(movie_ids))\n",
    "        rating_user_vertices = [user_ids_invmap[id_] for id_ in self.ratings['user_id'].values]\n",
    "        rating_movie_vertices = [movie_ids_invmap[id_] + len(user_ids)\n",
    "                                 for id_ in self.ratings['movie_id'].values]\n",
    "        valid_tensor = torch.from_numpy(self.ratings['valid'].values.astype('uint8'))\n",
    "        test_tensor = torch.from_numpy(self.ratings['test'].values.astype('uint8'))\n",
    "        g.add_edges(rating_user_vertices,\n",
    "                    rating_movie_vertices,\n",
    "                    data={'valid': valid_tensor, 'test': test_tensor})\n",
    "        g.add_edges(rating_movie_vertices,\n",
    "                    rating_user_vertices,\n",
    "                    data={'valid': valid_tensor, 'test': test_tensor})\n",
    "\n",
    "        return g, user_ids, movie_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(h, nodeset):\n",
    "    return h[nodeset]\n",
    "\n",
    "def put_embeddings(h, nodeset, new_embeddings):\n",
    "    n_nodes = nodeset.shape[0]\n",
    "    n_features = h.shape[1]\n",
    "    return h.scatter(0, nodeset[:, None].expand(n_nodes, n_features), new_embeddings)\n",
    "\n",
    "def random_walk_sampler(G, nodeset, n_traces, n_hops):\n",
    "    '''\n",
    "    G: DGLGraph\n",
    "    nodeset: 1D CPU Tensor of node IDs\n",
    "    n_traces: int\n",
    "    n_hops: int\n",
    "    return: 3D CPU Tensor or node IDs (n_nodes, n_traces, n_hops + 1)\n",
    "    '''\n",
    "    n_nodes = nodeset.shape[0]\n",
    "    traces = torch.zeros(n_nodes, n_traces, n_hops + 1, dtype=torch.int64)\n",
    "\n",
    "    for i in range(n_nodes):\n",
    "        for j in range(n_traces):\n",
    "            cur = nodeset[i]\n",
    "            for k in range(n_hops + 1):\n",
    "                traces[i, j, k] = cur\n",
    "                neighbors = G.successors(cur)\n",
    "                assert neighbors.shape[0] > 0\n",
    "                cur = neighbors[torch.randint(len(neighbors), ())]\n",
    "\n",
    "    return traces\n",
    "\n",
    "def random_walk_distribution(G, nodeset, n_traces, n_hops):\n",
    "    n_nodes = nodeset.shape[0]\n",
    "    n_available_nodes = G.number_of_nodes()\n",
    "    traces = random_walk_sampler(G, nodeset, n_traces, n_hops)\n",
    "    visited_nodes = traces[:, :, 1:].view(n_nodes, -1)  # (n_nodes, n_visited_other_nodes)\n",
    "    visited_counts = (\n",
    "            torch.zeros(n_nodes, n_available_nodes)\n",
    "            .scatter_add_(1, visited_nodes, torch.ones_like(visited_nodes, dtype=torch.float64)))\n",
    "    visited_prob = visited_counts / visited_counts.sum(1, keepdim=True)\n",
    "    return visited_prob\n",
    "\n",
    "def random_walk_distribution_topt(G, nodeset, n_traces, n_hops, top_T):\n",
    "    '''\n",
    "    returns the top T important neighbors of each node in nodeset, as well as\n",
    "    the weights of the neighbors.\n",
    "    '''\n",
    "    visited_prob = random_walk_distribution(G, nodeset, n_traces, n_hops)\n",
    "    return visited_prob.topk(1, top_T)\n",
    "\n",
    "def random_walk_nodeflow(G, nodeset, n_layers, n_traces, n_hops, top_T):\n",
    "    '''\n",
    "    returns a list of triplets (\n",
    "        \"active\" node IDs whose embeddings are computed at the i-th layer (num_nodes,)\n",
    "        weight of each neighboring node of each \"active\" node on the i-th layer (num_nodes, top_T)\n",
    "        neighboring node IDs for each \"active\" node on the i-th layer (num_nodes, top_T)\n",
    "    )\n",
    "    '''\n",
    "    nodeflow = []\n",
    "    cur_nodeset = nodeset\n",
    "    for i in reversed(range(n_layers)):\n",
    "        nb_weights, nb_nodes = random_walk_distribution_topt(G, nodeset, n_traces, n_hops, top_T)\n",
    "        nodeflow.insert((cur_nodeset, nb_weights, nb_nodes))\n",
    "        cur_nodeset = torch.cat([nb_nodes.view(-1), cur_nodeset]).unique()\n",
    "\n",
    "    return nodeflow\n",
    "\n",
    "class PinSageConv(nn.Module):\n",
    "    def __init__(self, in_features, out_features, hidden_features):\n",
    "        super(PinSageConv, self).__init__()\n",
    "\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.hidden_features = hidden_features\n",
    "\n",
    "        self.Q = nn.Linear(in_features, hidden_features)\n",
    "        self.W = nn.Linear(in_features + hidden_features, out_features)\n",
    "\n",
    "    def forward(self, h, nodeset, nb_nodes, nb_weights):\n",
    "        '''\n",
    "        h: node embeddings (num_total_nodes, in_features), or a container\n",
    "           of the node embeddings (for distributed computing)\n",
    "        nodeset: node IDs in this minibatch (num_nodes,)\n",
    "        nb_nodes: neighbor node IDs of each node in nodeset (num_nodes, num_neighbors)\n",
    "        nb_weights: weight of each neighbor node (num_nodes, num_neighbors)\n",
    "        return: new node embeddings (num_nodes, out_features)\n",
    "        '''\n",
    "        n_nodes, T = nb_nodes.shape[0]\n",
    "\n",
    "        h_nodeset = get_embeddings(h, nodeset)  # (n_nodes, in_features)\n",
    "        h_neighbors = get_embeddings(h, nb_nodes.view(-1)).view(n_nodes, T, self.in_features)\n",
    "\n",
    "        h_neighbors = F.relu(self.Q(h_neighbors))\n",
    "        h_agg = (nb_weights[:, :, None] * h_neighbors).sum(1) / nb_weights.sum(1, keepdim=True)\n",
    "\n",
    "        h_concat = torch.cat([h_nodeset, h_agg], 1)\n",
    "        h_new = F.relu(self.W(h_concat))\n",
    "        h_new /= h_new.norm(dim=1, keepdim=True)\n",
    "\n",
    "        return h_new\n",
    "\n",
    "class PinSage(nn.Module):\n",
    "    '''\n",
    "    Completes a multi-layer PinSage convolution\n",
    "    G: DGLGraph\n",
    "    feature_sizes: the dimensionality of input/hidden/output features\n",
    "    T: number of neighbors we pick for each node\n",
    "    n_traces: number of random walk traces to generate during sampling\n",
    "    n_hops: number of hops of each random walk trace during sampling\n",
    "    '''\n",
    "    def __init__(self, G, feature_sizes, T, n_traces, n_hops):\n",
    "        super(PinSage, self).__init__()\n",
    "\n",
    "        self.G = G\n",
    "        self.T = T\n",
    "        self.n_traces = n_traces\n",
    "        self.n_hops = n_hops\n",
    "\n",
    "        self.in_features = feature_sizes[0]\n",
    "        self.out_features = feature_sizes[-1]\n",
    "        self.n_layers = len(feature_sizes) - 1\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        for i in range(self.n_layers):\n",
    "            self.convs.append(PinSageConv(\n",
    "                feature_sizes[i], feature_sizes[i+1], feature_sizes[i+1]))\n",
    "\n",
    "    def forward(self, h, nodeset):\n",
    "        '''\n",
    "        Given a complete embedding matrix h and a list of node IDs, return\n",
    "        the output embeddings of these node IDs.\n",
    "        h: node embeddings (num_total_nodes, in_features), or a container\n",
    "           of the node embeddings (for distributed computing)\n",
    "        nodeset: node IDs in this minibatch (num_nodes,)\n",
    "        return: new node embeddings (num_nodes, out_features)\n",
    "        '''\n",
    "        nodeflow = random_walk_nodeflow(self.G, nodeset, self.n_layers, self.n_traces, self.n_hops, self.T)\n",
    "\n",
    "        for i, (nodeset, nb_weights, nb_nodes) in enumerate(nodeflow):\n",
    "            new_embeddings = self.convs[i](h, nodeset, nb_nodes, nb_weights)\n",
    "            h = put_embeddings(h, nodeset, new_embeddings)\n",
    "\n",
    "        return get_embeddings(h, nodeset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = os.path.join(\".\", \"movielens\")\n",
    "movielens = MovieLens(datadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nhtsai/.local/lib/python3.7/site-packages/dgl/base.py:45: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "dgl_movielens = movielens.todglgraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PinSage(\n",
       "  (convs): ModuleList(\n",
       "    (0): PinSageConv(\n",
       "      (Q): Linear(in_features=10, out_features=16, bias=True)\n",
       "      (W): Linear(in_features=26, out_features=16, bias=True)\n",
       "    )\n",
       "    (1): PinSageConv(\n",
       "      (Q): Linear(in_features=16, out_features=10, bias=True)\n",
       "      (W): Linear(in_features=26, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PinSage(dgl_movielens, [10, 16, 10], 3, 10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dgl.examples'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-4c469df6e91c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dgl.examples'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
