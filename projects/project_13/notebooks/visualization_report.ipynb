{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intended For Visualization Purposes Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (4.4.0.46)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /opt/conda/lib/python3.7/site-packages (from opencv-python) (1.18.5)\n"
     ]
    }
   ],
   "source": [
    "# !pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages needed to create dataframe and plot\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization Demo of RRT Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following few cells, images of the mapping algorithm will be displayed to show the RTT process of getting from point A to point B. The images are generated from the \"generate_rrt_vis.py\" python file respectively. These images below follow the test track followed with incremental steps showing the RRT algorithm creating nodes, before ultimately deciding on the best path. Further implementation involves pulling data/images from generated ROSbags followed by converting respective data into correct types. Afterwards, visualization could be outputted with the generated data to visualize each incremental node.\n",
    "\n",
    "Further implementation will involve integrating visualization seen below into interactive interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Test Track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/test_track.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Steps In"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/img_2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 35 Steps In"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/img_35.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 73 Steps In"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/img_73.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 130 Steps In"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/img_130.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 193 Steps In"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/img_193.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 196 Steps In"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/img_196.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, the same algorithm seen above is applied to a created masked grayscale Thunderhill track. The red dots represent the nodes that are branched out from the starting node. The green lines represent the branches that connect each respective red node. Finally the blue line connects the best path in the RRT* algorithm showing the navigation for the autonomous robot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RRT* Visualization Algorithm applied onto Thunderhill track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/out.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an image that shows a simulation of the Turtlebot navigating a test track. The visualizations show what the Turtlebot can see in through lidar and its respective cameras. Will be incorporated into final interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Premap Visualization on ROS/Gazebo/RViz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/ing2_premap.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an image of the final interactive interface. It allows a user to interact with this interface, thus interacting with the physical robot. More details regarding how the interface works is detailed in the repository. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/interface_final.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os \n",
    "# import matplotlib.pyplot as plt \n",
    "# path= \"pathtoyourfolder\"\n",
    "# list_=os.listdir(path)\n",
    "# for item in list_:\n",
    "#     plt.imshow(path+item)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing grayscale converstion code\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #! /usr/bin/python\n",
    "# \"\"\" Converts a list of list into gray-scale PNG image. \"\"\"\n",
    "# __copyright__ = \"Copyright (C) 2014 Guido Draheim\"\n",
    "# __licence__ = \"Public Domain\"\n",
    "\n",
    "# import zlib\n",
    "# import struct\n",
    "\n",
    "# def makeGrayPNG(data, height = None, width = None):\n",
    "#     def I1(value):\n",
    "#         return struct.pack(\"!B\", value & (2**8-1))\n",
    "#     def I4(value):\n",
    "#         return struct.pack(\"!I\", value & (2**32-1))\n",
    "#     # compute width&height from data if not explicit\n",
    "#     if height is None:\n",
    "#         height = len(data) # rows\n",
    "#     if width is None:\n",
    "#         width = 0\n",
    "#         for row in data:\n",
    "#             if width < len(row):\n",
    "#                 width = len(row)\n",
    "#     # generate these chunks depending on image type\n",
    "#     makeIHDR = True\n",
    "#     makeIDAT = True\n",
    "#     makeIEND = True\n",
    "#     png = b\"\\x89\" + \"PNG\\r\\n\\x1A\\n\".encode('ascii')\n",
    "#     if makeIHDR:\n",
    "#         colortype = 0 # true gray image (no palette)\n",
    "#         bitdepth = 8 # with one byte per pixel (0..255)\n",
    "#         compression = 0 # zlib (no choice here)\n",
    "#         filtertype = 0 # adaptive (each scanline seperately)\n",
    "#         interlaced = 0 # no\n",
    "#         IHDR = I4(width) + I4(height) + I1(bitdepth)\n",
    "#         IHDR += I1(colortype) + I1(compression)\n",
    "#         IHDR += I1(filtertype) + I1(interlaced)\n",
    "#         block = \"IHDR\".encode('ascii') + IHDR\n",
    "#         png += I4(len(IHDR)) + block + I4(zlib.crc32(block))\n",
    "#     if makeIDAT:\n",
    "#         raw = b\"\"\n",
    "#         for y in range(height):\n",
    "#             raw += b\"\\0\" # no filter for this scanline\n",
    "#             for x in range(width):\n",
    "#                 c = b\"\\0\" # default black pixel\n",
    "#                 if y < len(data) and x < len(data[y]):\n",
    "#                     c = I1(data[y][x])\n",
    "#                 raw += c\n",
    "#         compressor = zlib.compressobj()\n",
    "#         compressed = compressor.compress(raw)\n",
    "#         compressed += compressor.flush() #!!\n",
    "#         block = \"IDAT\".encode('ascii') + compressed\n",
    "#         png += I4(len(compressed)) + block + I4(zlib.crc32(block))\n",
    "#     if makeIEND:\n",
    "#         block = \"IEND\".encode('ascii')\n",
    "#         png += I4(0) + block + I4(zlib.crc32(block))\n",
    "#     return png\n",
    "\n",
    "# def _example():\n",
    "#     with open(\"cross3x3.png\",\"wb\") as f:\n",
    "#         f.write(makeGrayPNG([[0,255,0],[255,255,255],[0,255,0]]))\n",
    "\n",
    "\n",
    "# _example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
