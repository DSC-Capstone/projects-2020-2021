{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBDT vs Baseline Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not enough values to unpack (expected 2, got 0)\n"
     ]
    }
   ],
   "source": [
    "# import custom modules\n",
    "import sys\n",
    "sys.path.insert(0, \"../src/util\")\n",
    "sys.path.insert(0, \"../src/model\")\n",
    "sys.path.insert(0, \"../src/data_util\")\n",
    "\n",
    "# imports for model\n",
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.checkpoint as cp\n",
    "from torchvision import datasets, models, transforms\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from baseline import *\n",
    "\n",
    "from nbdt.model import SoftNBDT\n",
    "from nbdt.loss import SoftTreeSupLoss\n",
    "\n",
    "from wn_utils import *\n",
    "from graph import *\n",
    "from dir_grab import *\n",
    "from hierarchy import *\n",
    "from debug_data import *\n",
    "from write_to_json import *\n",
    "from loss import *\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> loaded data config\n",
      "---> loaded model config\n"
     ]
    }
   ],
   "source": [
    "with open('../config/data-params.json') as fh:\n",
    "    data_cfg = json.load(fh)\n",
    "    print('---> loaded data config')\n",
    "\n",
    "with open('../config/model-params.json') as fh:\n",
    "    model_cfg = json.load(fh)\n",
    "    print('---> loaded model config')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Begin model initialization...\n",
      "---> Finished model initialization.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model that was already trained\n",
    "model_weights = torch.load(os.path.join('..',data_cfg['hierarchyModelPath']))\n",
    "model, input_size = initialize_model(\n",
    "    model_cfg['modelName'],\n",
    "    model_cfg['nClasses'],\n",
    "    feature_extract = 'False'\n",
    ")\n",
    "model = model.to(device) # make model use GPU\n",
    "model.load_state_dict(model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test data loader\n",
    "data_transforms = {\n",
    "    'valid_snakes_r1': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "    \n",
    "# Create test datasets\n",
    "image_datasets = {\n",
    "    'valid_snakes_r1': datasets.ImageFolder(os.path.join('../' + data_cfg['dataDir'], 'valid_snakes_r1'), data_transforms['valid_snakes_r1'])  \n",
    "}\n",
    "    \n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {\n",
    "    x: torch.utils.data.DataLoader(\n",
    "        image_datasets[x],\n",
    "        batch_size=16,\n",
    "        shuffle=True,\n",
    "        num_workers=4\n",
    "    ) for x in [\n",
    "        'valid_snakes_r1'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "running_corrects = 0\n",
    "fscore = []\n",
    "\n",
    "# iterate over data\n",
    "for inputs, labels in dataloaders_dict['valid_snakes_r1']:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "    # statistics\n",
    "    labels_cpu = labels.cpu().numpy()\n",
    "    predictions_cpu = preds.cpu().numpy()\n",
    "    Fscore = f1_score(labels_cpu, predictions_cpu, average='macro')\n",
    "    fscore.append(Fscore)\n",
    "    running_corrects += torch.sum(preds == labels.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Test Acc: 0.6617 F: 0.516\n"
     ]
    }
   ],
   "source": [
    "epoch_acc = running_corrects.double() / len(dataloaders_dict['valid_snakes_r1'].dataset)\n",
    "epoch_fscore = np.average(np.array(fscore))\n",
    "\n",
    "print('{} Acc: {:.4f} F: {:.3f}'.format('CNN Test', epoch_acc, epoch_fscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbdt_model = SoftNBDT(\n",
    "    model = model,\n",
    "    dataset = 'snakes', \n",
    "    hierarchy='induced-densenet121',\n",
    "    path_graph = \"../data/hierarchies/snakes/graph-induced-densenet121.json\",\n",
    "    path_wnids = \"../data/wnids/snakes.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbdt_model.eval()\n",
    "\n",
    "nbdt_running_corrects = 0\n",
    "nbdt_fscore = []\n",
    "\n",
    "# iterate over data\n",
    "for inputs, labels in dataloaders_dict['valid_snakes_r1']:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = nbdt_model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "    # statistics\n",
    "    nbdt_labels_cpu = labels.cpu().numpy()\n",
    "    nbdt_predictions_cpu = preds.cpu().numpy()\n",
    "    nbdt_Fscore = f1_score(nbdt_labels_cpu, nbdt_predictions_cpu, average='macro')\n",
    "    nbdt_fscore.append(nbdt_Fscore)\n",
    "    nbdt_running_corrects += torch.sum(preds == labels.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NBDT Test Acc: 0.4450 F: 0.302\n"
     ]
    }
   ],
   "source": [
    "nbdt_epoch_acc = nbdt_running_corrects.double() / len(dataloaders_dict['valid_snakes_r1'].dataset)\n",
    "nbdt_epoch_fscore = np.average(np.array(nbdt_fscore))\n",
    "\n",
    "print('{} Acc: {:.4f} F: {:.3f}'.format('NBDT Test', nbdt_epoch_acc, nbdt_epoch_fscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>fscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline_cnn</th>\n",
       "      <td>0.661744</td>\n",
       "      <td>0.516375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nbdt</th>\n",
       "      <td>0.445032</td>\n",
       "      <td>0.301830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   acc    fscore\n",
       "baseline_cnn  0.661744  0.516375\n",
       "nbdt          0.445032  0.301830"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([\n",
    "    [epoch_acc.item(), epoch_fscore],\n",
    "    [nbdt_epoch_acc.item(), nbdt_epoch_fscore]\n",
    "])\n",
    "df.columns = ['acc', 'fscore']\n",
    "df.index = ['baseline_cnn', 'nbdt']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/out/nbdt_vs_baseline.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
