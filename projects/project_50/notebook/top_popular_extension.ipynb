{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains an adapted top popular recommender that takes into account workout video data from the Youtube API (views, likes, comments) and compares its performance with the regular top popular recommender, which is purely based on the number of interactions for each workout (for offline testing, this is just the number of Fitness Blender comments for each workout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amanda\\Anaconda3\\lib\\site-packages\\lightfm\\_lightfm_fast.py:10: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  \"LightFM was compiled without OpenMP support. \"\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import ndcg_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# get_data function from src\n",
    "import sys\n",
    "sys.path.insert(0,'../src/data')\n",
    "from model_preprocessing import get_data \n",
    "\n",
    "# no warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num users: 4026, num_items 580.\n"
     ]
    }
   ],
   "source": [
    "# get data: this assume data collection/preprocessing has been previously run\n",
    "data_dct = get_data('../data/preprocessed/user_item_interactions.csv') # dictionary containing training, testing, etc\n",
    "yt = pd.read_csv('../data/raw/workouts_yt.csv') # youtube api data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We adapt our original top popular model to include an option for taking into account youtube data. For example, you can specify to include youtube likes into the recommender. In this case, top popular will recommend the workouts with the highest combined interactions count and like count. Since the range/variation of these counts (interactions, views, likes, comments) may vary, these attributes are first scaled to a value between 0 and 1 using sklearn's MinMaxScaler before being summed up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from src/models/top_popular.py\n",
    "\n",
    "def top_popular(ui_df, yt_df, include=None, k=None):\n",
    "    \"\"\"\n",
    "    Adapted top popular (different than the one in seen in src/models/top_popular.py used for offline testing)\n",
    "    \n",
    "    Arguments:\n",
    "    - ui_df: User-item interactions dataframe\n",
    "    - yt_df: Dataframe from youtube API\n",
    "    - include: List of attributes from youtube API to use in the recommender. If none, \n",
    "               this recommender is the same as the regular top popular model seen in \n",
    "               src/models/top_popular.py\n",
    "    - k: Top k recommendations are returned. If None, all recommendations are returned.\n",
    "    \n",
    "    Returns:\n",
    "    - preds: List of predicted workout ids, with highest ranked first. Workout ids are external workout ids\n",
    "    - scores: Corresponding scores to the predictions. Note: with the regular top popular recommender, \n",
    "              the score of each workout is the number of interactions for that workout. If include is not\n",
    "              None, the scores will be the sum of the interactions and specified youtube attributes, \n",
    "              which are each scaled to a number between 0 and 1 with MinMaxScaler.\n",
    "    \"\"\"\n",
    "    if include is None: # same as original top_popular recommender\n",
    "        workout_counts = ui_df.groupby(\n",
    "            'workout_id').size().sort_values(ascending=False)\n",
    "        preds = np.array(workout_counts.index)\n",
    "        scores = np.array(workout_counts.values)\n",
    "\n",
    "    else:\n",
    "        mms = MinMaxScaler()\n",
    "        workout_counts = ui_df.groupby('workout_id').size()\n",
    "        scores_scaled = mms.fit_transform(np.array(list(workout_counts)).reshape(-1,1)).reshape(1,-1)[0] # scale interaction counts\n",
    "        yt_scaled = mms.fit_transform(yt_df[['view_count','like_count','comment_count']]) # scale the youtube attributes\n",
    "        \n",
    "        # sum to get final score\n",
    "        if 'view_count' in include:\n",
    "            scores_scaled += yt_scaled[:,0]\n",
    "        if 'like_count' in include:\n",
    "            scores_scaled += yt_scaled[:,1]\n",
    "        if 'comment_count' in include:\n",
    "            scores_scaled += yt_scaled[:,2]\n",
    "        \n",
    "        # get final predictions/scores sorted\n",
    "        tot = pd.Series(scores_scaled,index=workout_counts.index).sort_values(ascending=False)\n",
    "        preds = np.array(tot.index)\n",
    "        scores = np.array(tot.values)\n",
    "        \n",
    "    if k is None:\n",
    "        return preds, scores\n",
    "    else:\n",
    "        return preds[:k], scores[:k]\n",
    "    \n",
    "def get_target_scores(external_indices, scores, item_map):\n",
    "    \"\"\"\n",
    "    Same as seen in src/models/top_popular.py\n",
    "    \n",
    "    Helper function to get input of sklearn ncdg:\n",
    "    Given movie ids and their popularity score, as well as a dictionary mapping\n",
    "    external ids to LightFM internal ids, return the list of popularity scores\n",
    "    by LightFM internal id ordering\n",
    "    \"\"\"\n",
    "    internal_indices = [item_map[i] for i in external_indices]\n",
    "    scores_by_internal = np.zeros(len(item_map.values()))\n",
    "    scores_by_internal.put(internal_indices, scores)\n",
    "    return scores_by_internal\n",
    "\n",
    "\n",
    "def evaluate_top_popular(train_df, test_ui_matrix, item_map, yt_df, include=None, k=None):\n",
    "    \"\"\"\n",
    "    Adapted to use new top popular model.\n",
    "    \n",
    "    Takes in training/testing data and returns average NDCG\n",
    "    for top popular reccomender\n",
    "    \"\"\"\n",
    "    y_true = test_ui_matrix.toarray()\n",
    "    external_indices, scores = top_popular(train_df, yt_df, include=include)\n",
    "    y_score = get_target_scores(external_indices, scores, item_map)\n",
    "    y_scores = [list(y_score)]*(y_true.shape[0])\n",
    "\n",
    "    return ndcg_score(y_true, y_scores, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the recommender on a training dataset and evaluate the NDCG score on the testing dataset. We compare the original top popular recommender with models including view count, like counts, comment count, both individually and combined. We find that the NDCG for the original top popular recommender performs the best and adding data from Youtube decreases the NDCG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09887370285575565\n"
     ]
    }
   ],
   "source": [
    "# the original top popular recommender\n",
    "k=20 # k parameter for ndcg\n",
    "top_pop_ndcg = evaluate_top_popular(data_dct['train_df'],\n",
    "                                    data_dct['test_ui_matrix'],\n",
    "                                    data_dct['item_map'],\n",
    "                                    yt,\n",
    "                                    include=None,\n",
    "                                    k=k)\n",
    "print(str(top_pop_ndcg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07385714923369312\n"
     ]
    }
   ],
   "source": [
    "# including view count\n",
    "top_pop_ndcg = evaluate_top_popular(data_dct['train_df'],\n",
    "                                    data_dct['test_ui_matrix'],\n",
    "                                    data_dct['item_map'],\n",
    "                                    yt,\n",
    "                                    include=['view_count'],\n",
    "                                    k=k)\n",
    "print(str(top_pop_ndcg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07417811298862918\n"
     ]
    }
   ],
   "source": [
    "# including like count\n",
    "top_pop_ndcg = evaluate_top_popular(data_dct['train_df'],\n",
    "                                    data_dct['test_ui_matrix'],\n",
    "                                    data_dct['item_map'],\n",
    "                                    yt,\n",
    "                                    include=['like_count'],\n",
    "                                    k=k)\n",
    "print(str(top_pop_ndcg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08445299011940773\n"
     ]
    }
   ],
   "source": [
    "# including comment count\n",
    "top_pop_ndcg = evaluate_top_popular(data_dct['train_df'],\n",
    "                                    data_dct['test_ui_matrix'],\n",
    "                                    data_dct['item_map'],\n",
    "                                    yt,\n",
    "                                    include=['comment_count'],\n",
    "                                    k=k)\n",
    "print(str(top_pop_ndcg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06464159834645176\n"
     ]
    }
   ],
   "source": [
    "# includinng view_count, like_count, comment_count\n",
    "top_pop_ndcg = evaluate_top_popular(data_dct['train_df'],\n",
    "                                    data_dct['test_ui_matrix'],\n",
    "                                    data_dct['item_map'],\n",
    "                                    yt,\n",
    "                                    include=['view_count','like_count','comment_count'],\n",
    "                                    k=k)\n",
    "print(str(top_pop_ndcg))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
