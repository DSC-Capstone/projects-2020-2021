,phrase,score
0,natural language processing,0.8389898381144593
1,natural language,0.757930793616169
2,computational linguistics,0.7409695833739589
3,cross validation,0.7186582030772644
4,named entity recognition,0.7059102070558253
5,pos tagging,0.6962150990792717
6,lstm crf,0.6061228873292622
7,chicago,0.5937468333221413
8,japan,0.5710259295312059
9,f1,0.5370410826647415
10,china,0.5300056832699409
11,nz,0.5242887994528876
12,loc,0.5098450065856339
13,mi,0.500274401189734
14,ace,0.49129744619783267
15,language,0.4905798848555661
16,flair,0.4896007122602068
17,liu,0.4865244159998513
18,di,0.4730859886692311
19,random,0.4728966861312618
20,tagging,0.4665898264223114
21,entity,0.4609019605085798
22,ner,0.45688296394713795
23,cross,0.454332960701353
24,corrected,0.45282638794129015
25,label,0.4511409534704517
26,annotation,0.4477189725124451
27,contextualized,0.44659333816430236
28,linguistics,0.4460103661077038
29,dataset,0.43897912696593433
30,pooled,0.43864567324756504
31,ci,0.43714517891861115
32,learning,0.4335979141596519
33,boosting,0.4325975107817677
34,experiments,0.43192648851122806
35,data,0.4309154314373679
36,test,0.4305807957561273
37,score,0.42997622846949796
38,extensive experiments,0.42958735844683504
39,xi,0.4295402902131057
40,set,0.42670531299836606
41,estimation,0.4252022281221945
42,results,0.42517016410715025
43,misc,0.42445665879294975
44,agreement,0.4241977635071427
45,wi,0.4237240343187178
46,conference,0.42269472177604983
47,correction,0.4224471152302902
48,international,0.421989231440688
49,mistake,0.42062610720220206
50,team,0.41821340384949507
51,lstm,0.41761503371516673
52,neural,0.4157519656427921
53,base,0.4153450022797689
54,table,0.4143794681291889
55,weighted,0.4137785462575457
56,crf,0.41374152161072136
57,prediction,0.41346302343922553
58,peters,0.413371882133233
59,org,0.41111617279163765
60,standard,0.41042379184261163
61,f1 score,0.41023123422421026
62,deep,0.4099345883803685
63,figure,0.40918975212452857
64,section,0.4060327780161838
65,labeling,0.40498198765286736
66,stable,0.40301282227136753
67,model,0.4024603359120544
68,human,0.4015716336613478
69,character,0.40009569434739145
70,sentence,0.39598736239678817
71,training,0.39423779698185046
72,specifically,0.3931233262138062
73,final,0.3907718258989822
74,ratio,0.3888858090593277
75,knowledge,0.3888098994377558
76,weight,0.3817772704746809
77,labelled,0.3816486301410948
78,algorithms,0.38161198194391494
79,mistakes,0.37922923752575044
80,computational,0.37742681200049943
81,evaluation,0.37665853933677046
82,word,0.3763885818125776
83,number,0.3712114596953177
84,algorithm,0.37000627864337043
85,models,0.367678915848474
86,precision,0.3666915970549604
87,test set,0.36439713255136097
88,framework,0.3607300906315555
89,fold,0.3572690932309601
90,marked,0.35672835009079296
91,sequence,0.3537040067954682
92,benchmark,0.3534707153620004
93,processing,0.3524443110726218
94,potential,0.35239913673513745
95,weights,0.3514888802398083
96,examples,0.3507476073424807
97,default,0.35072809173256786
98,low,0.3491497643681525
99,quality,0.347761453574894
100,pages,0.3443388215593145
101,module,0.34365845585658905
102,folds,0.3422795455438946
103,high,0.3408763149996545
104,performance,0.34076049089317156
105,step,0.3386447008482335
106,smaller,0.3313797257641544
107,labels,0.32909066744839655
108,randomly,0.32867303209457355
109,guideline,0.32867031986593015
110,proposed,0.3283441634341098
111,similar,0.3280180223417595
112,annotated,0.3253162374633461
113,iterations,0.32395764544441397
114,methods,0.3230879445254904
115,process,0.3217371144799868
116,end,0.32119705109471597
117,correct,0.3196103313719336
118,estimations,0.3189693549163732
119,entities,0.3189606418355327
120,runs,0.3176129347904494
121,annotations,0.3161660804603648
122,parameters,0.31551720531875377
123,higher,0.31245249787670726
124,original,0.3121471281820506
125,sentences,0.3115990421928884
126,compared,0.3088239923773091
127,won,0.30877504118909266
128,based,0.30600499676703297
129,lowers,0.30177879512588357
130,evaluate,0.299507252107334
131,datasets,0.29666202926058866
132,train,0.2952650374067725
133,et al,0.29286332286643557
134,annotators,0.290159092180652
135,detected,0.29010773815220636
136,named,0.28657534343892754
137,trained,0.28454948098120253
138,identified,0.28060426596710625
139,handle,0.2792911788045069
140,study,0.2686439433093613
141,observe,0.2655138948148978
142,conduct,0.2644844158539691
143,re,0.25872196559398136
144,identify,0.25762617717527436
145,i.e,0.25485018362874196
146,proceedings,0.2544773056549481
147,w,0.24623829759190374
148,ner models,0.24221400836619225
149,named entity,0.2349541547073709
150,m,0.22590597498849285
151,most,0.2212462390613035
152,k,0.22087850632295053
153,d,0.21854065079125853
154,training set,0.2162701161104848
155,in,0.19396261452776653
156,f,0.1818952945840323
157,first,0.1817345447163748
158,n,0.17775047748193834
159,per,0.17720753654926166
160,as,0.17703545080040664
161,10,0.17595682072200636
162,therefore,0.1747098101743766
163,t,0.17125759440782215
164,i,0.1712297254168487
165,following,0.17052322273904652
166,on,0.16952436187166064
167,if,0.1695219776854734
168,while,0.16875597156620833
169,thus,0.16583172575255417
170,then,0.16485050496734074
171,there,0.16352257679125168
172,for,0.16331686241057666
173,further,0.16285636326613928
174,do,0.16192205023693057
175,one,0.1593819659491028
176,among,0.15895008098227567
177,however,0.1588287249035838
178,three,0.15654951679793216
179,1,0.1564530252993542
180,each,0.15516272929036914
181,these,0.15470835758697976
182,during,0.15466044239882715
183,using,0.1532842579209388
184,because,0.15323616908505208
185,the,0.1531626529708617
186,this,0.15062866952531073
187,new,0.14944330898084282
188,through,0.1489447856128995
189,also,0.14704564996631878
190,=,0.14689764425964086
191,at,0.14674322556883349
192,two,0.14642239463755502
193,such,0.1462913846191334
194,we,0.14415598052638542
195,a,0.1423979025363237
196,the art,0.1422910103183126
197,but,0.1421728010171797
198,our,0.140816398799189
199,to,0.14068197575706307
200,better,0.14041247705125104
201,even,0.13961306016517497
202,+,0.1395216613860428
203,it,0.13843278348757956
204,training data,0.13747429858065624
205,they,0.1356730012132075
206,some,0.13545094569497548
207,an,0.13439161576519326
208,when,0.1338857890772698
209,more,0.13380316384445487
210,language models,0.1331815854135081
211,ner model,0.13308204766943682
212,2011,0.13240488087490654
213,leads to,0.13125972867204724
214,all,0.1305218370604959
215,0.7,0.1297435277962004
216,way,0.12966378299958445
217,2003,0.12912620435720334
218,of,0.1290981268977694
219,other,0.1283727918159936
220,2019,0.12802242332045594
221,4,0.12773743693819462
222,2017,0.126644733874016
223,by,0.12606099993819808
224,7,0.12393337445669234
225,1999,0.12341349157307886
226,or,0.12333151695558374
227,different,0.1217863431263778
228,2,0.12103765045886872
229,3,0.1202864811764962
230,both,0.12025763544242868
231,with,0.11944823719279449
232,state of,0.11936560990449818
233,17,0.11905010305277504
234,from,0.11886942381422747
235,only,0.1187094565150511
236,2016,0.11842309127912515
237,used,0.11801002062235219
238,5,0.11785202271635375
239,not,0.11775907861829411
240,any,0.11694309679544261
241,2018,0.11512708818263342
242,those,0.11502232366117059
243,than,0.11498676633781067
244,about,0.11246356603721004
245,being,0.11229714666730012
246,find,0.1108381406754884
247,their,0.11071592474897489
248,its,0.11054007452311067
249,use,0.10632063441350391
250,where,0.10574523017132244
251,should,0.10572804493925879
252,into,0.10470789676544096
253,may,0.10462117236480421
254,effectiveness of,0.10385711922791384
255,them,0.10342594835529656
256,able to,0.10318348980586967
257,and,0.10227120441372207
258,which,0.10105618689235188
259,has,0.10059402405969274
260,will,0.09969848781348079
261,was,0.09965219280556774
262,can,0.09520386284083907
263,have,0.09432653203514645
264,is,0.09357363928573531
265,be,0.09350381523822077
266,that,0.09334297523428495
267,are,0.09328459096740994
268,proposed framework,0.09165430110038168
269,the same,0.0899666030728608
270,ner dataset,0.08832731461390485
271,for example,0.08385892095480627
272,peters et al,0.07801225910664847
273,model training,0.07459261415060345
274,the training set,0.06562387104607982
275,estimation module,0.05165467852912436
276,the number of,0.04953159013528525
277,the test set,0.04127526243426981
278,= 1,0.03817673137113364
279,k = 10,0.03603728448498487
280,the weights of,0.03560373522666722
281,re evaluate,0.028478773351414514
282,the original,0.026843345670322954
283,based on,0.023579610142727706
284,each sentence,0.02051079664994436
285,conference on,0.020459942369079585
286,performance of,0.02016949469126302
287,number of,0.020035518503473695
288,the results,0.01876075024334278
289,k =,0.018029912843834532
290,the performance,0.011236466669830242
291,the training,0.010676835507552423
292,marked as,0.010390939853424078
293,the annotation,0.009334995208738619
294,the test,0.009194639938556595
295,labelled as,0.008713350240723885
296,mistakes in,0.008608924843665745
297,proceedings of,0.008593255586821835
298,the label,0.00768192749752515
299,the potential,0.007083669703312037
300,the weights,0.005926281997584774
301,most of,0.005549639617485868
