{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarities = pd.read_csv(\"./polarities.csv\").dropna()\n",
    "polarities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarities['user/name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarities['flagged'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = polarities[['flagged', 'pol_rightness', 'credibility', 'moderacy']]\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_flagged = data[data['flagged']]['pol_rightness']\n",
    "pol_unflagged = data[data['flagged'] == False]['pol_rightness']\n",
    "sns.kdeplot(pol_flagged, shade=True).set_title(\"Political Polarization\")\n",
    "sns.kdeplot(pol_unflagged, shade=True)\n",
    "plt.legend(title='Tweet Liked', loc='upper left', labels=['Flagged', 'Unflagged'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_flagged = data[data['flagged']]['credibility']\n",
    "pol_unflagged = data[data['flagged'] == False]['credibility']\n",
    "sns.kdeplot(pol_flagged, shade=True).set_title(\"Credibility Polarization\")\n",
    "sns.kdeplot(pol_unflagged, shade=True)\n",
    "plt.legend(title='Tweet Liked', loc='upper left', labels=['Flagged', 'Unflagged'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_flagged = data[data['flagged']]['moderacy']\n",
    "pol_unflagged = data[data['flagged'] == False]['moderacy']\n",
    "sns.kdeplot(pol_flagged, shade=True).set_title(\"Moderacy Polarization\")\n",
    "sns.kdeplot(pol_unflagged, shade=True)\n",
    "plt.legend(title='Tweet Liked', loc='upper left', labels=['Flagged', 'Unflagged'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining Correlation  \n",
    "This section looks at whether there is a quantifiable and/or visual correlation between each of the three dimensions. Each of the below plots is made up of points, each one representing a user. The color of the point indicates whether that user was one who retweeted a flagged tweet or an unflagged tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Political vs Credibility**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = polarities[['pol_rightness', 'credibility']]\n",
    "sns.scatterplot(x=data['pol_rightness'], y=data['credibility'],\n",
    "                hue=polarities['flagged']).set_title(\"User Political verus Credibility Polarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Correlation Matrix\")\n",
    "print(data.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Political vs Moderacy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = polarities[['pol_rightness', 'moderacy']]\n",
    "sns.scatterplot(x=data['pol_rightness'], y=data['moderacy'],\n",
    "                hue=polarities['flagged']).set_title(\"User Political vs Moderacy Polarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Correlation Matrix\")\n",
    "print(data.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Moderacy vs Credibility**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = polarities[['moderacy', 'credibility']]\n",
    "sns.scatterplot(x=data['credibility'], y=data['moderacy'],\n",
    "                hue=polarities['flagged']).set_title(\"User Credibility verus Moderacy Polarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Correlation Matrix\")\n",
    "print(data.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1\n",
    "I will perform a permutation test for each dimension. That is, for one dimension I will calculate the difference between the sample means for all polarity scores for the flagged tweets group and then for the unflagged tweets groups. I will define the test statistic as the difference between those two means. I will then shuffle the flagged/unflagged labels and then recalculate the statistic. I will do this 100 times then calculate the p value.  \n",
    "  \n",
    "**Permutation Test:**  \n",
    "  \n",
    "Test Statistic: Define the test statistic as the difference between the sample means for the flagged and unflagged group for one dimension  \n",
    "  \n",
    "Null Hypothesis: There is no difference in the polarity scores between the flagged and unflagged groups  \n",
    "  \n",
    "Alternative Hypothesis: There is some difference in the polarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining functions for use in permutation test\n",
    "def mean_diff(data, dim):\n",
    "    return np.mean(data[data['flagged'] == True][dim]) - np.mean(data[data['flagged'] == False][dim])\n",
    "\n",
    "def permutation_test(data, n_reps, dim):\n",
    "    # Observed statistic\n",
    "    obs = mean_diff(data, dim)\n",
    "    \n",
    "    # Running and permuting n_reps of the data\n",
    "    trials = []\n",
    "    for i in range(n_reps):\n",
    "        shuffled_impres = (\n",
    "            data['flagged']\n",
    "            .sample(replace=False, frac=1)\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "        shuffled = (\n",
    "            data\n",
    "            .assign(**{'flagged': shuffled_impres})\n",
    "        )\n",
    "        trials.append(mean_diff(shuffled, dim))\n",
    "    return np.count_nonzero(np.array(trials) >= obs) / n_reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's run the test for the political polarity\n",
    "data = polarities[['pol_rightness', 'credibility', 'moderacy', 'flagged']]\n",
    "outcomes = []\n",
    "dimensions = ['pol_rightness', 'credibility', 'moderacy']\n",
    "for dim in dimensions:\n",
    "    out = (dim, permutation_test(data, 1000, dim))\n",
    "    outcomes.append(out)\n",
    "    print('Dimension: ' + out[0])\n",
    "    print('p-value: ' + str(out[1]) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluating:**  \n",
    "The break down of the tests for each dimension is reported above. Notice that for the credibility and the moderacy dimensions, there is a more significant difference between the two groups than there is for the poltical dimension. Hopefully with more data this becomes more apparent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2\n",
    "We will compare the data for each dimension using a t-test. Under this test we assume the data is normally distributed with the same variance. We will perform a two-sided test between the flagged and unflagged group for each dimension.  \n",
    "  \n",
    "**Two-sided t-test**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = []\n",
    "for dim in dimensions:\n",
    "    flagged = data[data['flagged'] == True][dim]\n",
    "    unflagged = data[data['flagged'] == False][dim]\n",
    "    out = (dim, stats.ttest_ind(flagged, unflagged, equal_var=True))\n",
    "    outcomes.append(out)\n",
    "    print('Dimension: ' + out[0])\n",
    "    print('p-value: ' + str(out[1]) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outcome** \n",
    "We can see a very similar outcome as the permutation test, as we would expect. Next we will test the one-sided t-test for both groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3\n",
    "We will test whether flagged group has statistically significantly higher or lower polarity scores than the unflagged group for both dimensions. We will use a one-sided t-test.  \n",
    "**One-sided t-test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = []\n",
    "for dim in dimensions:\n",
    "    flagged = data[data['flagged'] == True][dim]\n",
    "    unflagged = data[data['flagged'] == False][dim]\n",
    "    out = (dim, stats.ttest_ind(flagged, unflagged, equal_var=True))\n",
    "    outcomes.append(out)\n",
    "    print('Dimension: ' + out[0])\n",
    "    print('p-value: ' + str(out[1][1]/2))\n",
    "    print('Test Statistic: ' + str(out[1][0]) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outcome**  \n",
    "First, let alpha = 0.1. Next, we can derive the outcome of the one-sided as the flagged polarities are significantly greater than the unflagged polarities if the p-value < alpha and the test statistic is > 0. Likewise if the test statistic is < 0 then it means the flagged polarities are significantly lesser than the unflagged polarities. Notice here that while there is no statistically significant outcome for the moderacy and credibility dimensions, we can see that the political polarity of users who retweeted a flagged tweet is statistically significantly greater than those of the users who retweeted an unflagged tweet. This is what we would expect since the tweets being flagged are coming from a user who is generally aligned with right wing views so the users that are interacting with a flagged tweet tend to have a higher polarity tending towards the right.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
