{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "from IPython.display import Image, display\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config/results-params.json') as fh:\n",
    "    results_cfg = json.load(fh)\n",
    "dims = results_cfg['dims']\n",
    "outdir = results_cfg['outdir']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarities = pd.read_csv(os.path.join(results_cfg['user_data_path'], 'polarities.csv')).dropna().drop(columns=['Unnamed: 0'])\n",
    "polarities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarities['user/name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarities['flagged'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = polarities[['flagged'] + results_cfg['dims']]\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dim in results_cfg['dims']:\n",
    "    display(Image(filename=os.path.join(results_cfg['outdir'], 'kde_plot_{}.png'.format(dim))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining Correlation  \n",
    "This section looks at whether there is a quantifiable and/or visual correlation between each of the three dimensions. Each of the below plots is made up of points, each one representing a user. The color of the point indicates whether that user was one who retweeted a flagged tweet or an unflagged tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dims)):\n",
    "    for j in range(i+1, len(dims)):\n",
    "        display(Image(filename=os.path.join(results_cfg['outdir'], 'correlation_{}_{}.png'.format(dims[i], dims[j]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarities[dims].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1\n",
    "I will perform a permutation test for each dimension. That is, for one dimension I will calculate the difference between the sample means for all polarity scores for the flagged tweets group and then for the unflagged tweets groups. I will define the test statistic as the difference between those two means. I will then shuffle the flagged/unflagged labels and then recalculate the statistic. I will do this 100 times then calculate the p value.  \n",
    "  \n",
    "**Permutation Test:**  \n",
    "  \n",
    "Test Statistic: Define the test statistic as the difference between the sample means for the flagged and unflagged group for one dimension  \n",
    "  \n",
    "Null Hypothesis: There is no difference in the polarity scores between the flagged and unflagged groups  \n",
    "  \n",
    "Alternative Hypothesis: The flagged users have a higher polarity score in a respective dimension than the unflagged users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dim in dims:\n",
    "    with open(os.path.join(outdir, 'perm_test_{}.json'.format(dim))) as fh:\n",
    "        cfg = json.load(fh)\n",
    "        print(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluating:**  \n",
    "The break down of the tests for each dimension is reported above. Notice that for the credibility and the moderacy dimensions, there is a more significant difference between the two groups than there is for the poltical dimension. Hopefully with more data this becomes more apparent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2\n",
    "We will compare the data for each dimension using a t-test. Under this test we assume the data is normally distributed with the same variance. We will perform a two-sided test between the flagged and unflagged group for each dimension.  \n",
    "  \n",
    "**Two-sided t-test**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dim in dims:\n",
    "    with open(os.path.join(outdir, 'two_sided_ttest_{}.json'.format(dim))) as fh:\n",
    "        cfg = json.load(fh)\n",
    "        print(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outcome** \n",
    "We can see a very similar outcome as the permutation test, as we would expect. Next we will test the one-sided t-test for both groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3\n",
    "We will test whether flagged group has statistically significantly higher or lower polarity scores than the unflagged group for both dimensions. We will use a one-sided t-test.  \n",
    "**One-sided t-test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dim in dims:\n",
    "    with open(os.path.join(outdir, 'one_sided_ttest_{}.json'.format(dim))) as fh:\n",
    "        cfg = json.load(fh)\n",
    "        print(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outcome**  \n",
    "First, let alpha = 0.1. Next, we can derive the outcome of the one-sided as the flagged polarities are significantly greater than the unflagged polarities if the p-value < alpha and the test statistic is > 0. Likewise if the test statistic is < 0 then it means the flagged polarities are significantly lesser than the unflagged polarities. Notice here that while there is no statistically significant outcome for the moderacy and credibility dimensions, we can see that the political polarity of users who retweeted a flagged tweet is statistically significantly greater than those of the users who retweeted an unflagged tweet. This is what we would expect since the tweets being flagged are coming from a user who is generally aligned with right wing views so the users that are interacting with a flagged tweet tend to have a higher polarity tending towards the right.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
