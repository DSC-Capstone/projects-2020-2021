<!DOCTYPE html>
<html lang="en">
  <head>
    <title>AutoLibrary</title>
    {% load static %}
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <link rel="stylesheet" href="{% static 'autolibrary/css/main.css' %}" type="text/css" media="screen, projection" />
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
  </head>
  <body style="background-color:rgb(175, 161, 130);">
    <div id="outer-wrapper">
      <div id="inner-wrapper">
        <div id="content-wrapper">
          <div id="content">
            <ul id="nav">
              <li><a href="http://127.0.0.1:8000/autolibrary">AutoLibrary</a></li>
              <li><a href="http://yichunren.pythonanywhere.com/blog">Blog</a></li>
              <li><a target="_blank" rel="noopener noreferrer" href="https://github.com/jfan1998/AutoLibrary">Code</a></li>
              <li><a href="http://127.0.0.1:8000/contact">Contact Us</a></li>
            </ul>
            <div id="content-inner">
              <div class="content-full">
                <h1 style="text-align: center;">AutoLibrary</h1><br><hr><br>
                <h2 id='Introduction'>Introduction</h2><br>
                <p class="intro">
                  When encountering scientific papers, it is challenging for readers themselves to find other related works. First of all, it is hard to identify keywords that summarize the papers to search for similar papers. This dilemma is most common if readers are not familiar with the domains of papers that they are reading. Meanwhile, traditional recommendation models based on user profile and collection data are not applicable for recommending similar works. Some existing digital libraries‚Äô recommender systems utilize phrase mining methods such as taxonomy construction and topic modeling, but such methods fail to catch the specific topics of the paper. AutoLibrary is designed to address these difficulties, where users can input a scientific paper and get the most related papers.
                </p>
                <img src="{% static 'blog/workflow.png' %}" alt="Workflow" height="100%" width="80%" style="display: block; margin-left: auto; margin-right: auto;">
                <br>
                <p class="intro">
                  AutoLibrary solves the dilemma via a text analyzer method called AutoPhrase. AutoPhrase is a domain-independent phrase mining method developed by Jingbo Shang et al. (2018) that can automatically extract quality phrases from the input paper. After users upload the paper and select the fields of study of the paper, AutoLibrary utilizes AutoPhrase and our pre-trained domain datasets to return high-quality domain-specific keywords that could represent the paper. While AutoLibrary uses the top three keywords to search on Semantic Scholar for similar works at first, users could also customize the selection of the high-quality phrases or enter their own keywords to explore other related works. Based on the experiments and result analysis, AutoLibrary outperforms other similar text analyzer applications efficiently and effectively across different scientific fields. AutoLibrary is beneficial as it eases the pain point of manually extracting accurate, specific keywords from papers and provides a customized user experience for finding related papers of various domains and subdomains.
                </p>
                <hr><br>

                <h2 id='Methodology'>Methodology</h2><br>
                <p class="intro">
                  In this section we will introduce the techniques used in AutoLibrary.
                </p>
                <ul>
                  <li style="margin-left: 2%;">
                    <p class="intro">AutoPhrase</p>
                  </li>
                  <img src="{% static 'blog/autophrase.png' %}" alt="AutoPhrase" height="100%" width="80%" style="display: block; margin-left: auto; margin-right: auto;">
                  <br>
                  <ol>
                    <li style="margin-left: 5%; margin-top: -2%; margin-bottom: 0%;">
                      <p class="intro"><i>Robust Positive-Only Distant Training</i></p>
                    </li>
                    <p class="intro" style="margin-left: 8%; margin-top: -2%; margin-bottom: 0%;">
                      This technique uses general knowledge bases like Wikipedia to eliminate the need for domain experts to manually label candidate phrases with binary labels. 
                    </p>
                    <p class="intro" style="margin-left: 8%; margin-top: 2%;">
                      Candidate phrases from the corpus that match the high quality phrases from the general knowledge base are routed to the positive pool. The inferior phrases leftover are routed to the negative pool. Because not all high quality phrases may be in the general knowledge base, some phrases could have been incorrectly routed to the negative pool. To reduce such a noise in the negative pool, we randomly sample K labels from each of the pools as a size-2K subset. It is a perturbed training set as there could be ùúπ wrongly labeled phrases in the sampled negative pool that should have been positive. Then we train with an unpruned decision tree because of its low training error. As long as a positive and negative phrase have different features, accuracy will always be 100%. From these decision trees, we define a phrase‚Äôs quality score as such: out of all the trees, what fraction of them predicted this phrase to be a quality phrase.
                    </p>
                    <li style="margin-left: 5%; margin-top: -2%; margin-bottom: 0%;">
                      <p class="intro"><i>POS-Guided Phrasal Segmentation</i></p>
                    </li>
                    <p class="intro" style="margin-left: 8%; margin-top: -2%; margin-bottom: 0%;">
                      Unlike previous work that punish the same-length phrase candidates in the same way, POS-guided phrasal segmentation measures the completeness of the phrases while considering the corpora‚Äôs context by taking advantage of sentence structure since there are inherent divisions in sentences by POS where many phrases reside.
                    </p>
                    <p class="intro" style="margin-left: 8%; margin-top: 2%;">
                      There are two parts to this process. The first is to tag words with their POS (part-of-speech) and create a sequence of pairs out of the corpus, where a pair is <word, POS tag>. The second is the phrasal segmentation process which builds on the pairs. This process creates m segments out of the sequence, each segment separated using a boundary index sequence. For each segment, we generate the boundary end index using the start index and given sequence. We use a multinomial distribution to create the word sequence, and compute the quality of a sequence as a segment. Then we maximize the joint log likelihood for a word sequence and boundary index sequence using the POS-Guided Phrasal Segmentation algorithm to return the ideal segmentation.
                    </p>
                  </ol>

                  <li style="margin-left: 2%;">
                    <p class="intro">Dataset</p>
                  </li>
                  <img src="{% static 'blog/dataset.png' %}" alt="Dataset" height="70%" width="70%" style="display: block; margin-left: auto; margin-right: auto;" />
                  <p class="intro" style="margin-left: 5%; margin-top: 2%;">
                    Since it is hard to ensure the significance of quality phrases generated from a single input paper to both the paper and its domain, we build a dataset that contains the quality phrases of different domains. To do this, we utilize the arXiv dataset available on Kaggle, which contains information about more than 1.7 million scholarly articles across STEM. We split the dataset into domains and subdomains, and extract corresponding quality phrases by running AutoPhrases on the corpora of each. After the user inputs a document and selects a domain, we use quality scores of the pre-obtained quality phrases for the specific domain to apply weights to the AutoPhrase results of the input document. In this way we can rank the phrases again and filter out unimportant phrases to the domain. Then the remaining phrases with the highest quality scores will be used for search on Semantic Scholar.
                  </p>

                  <li style="margin-left: 2%;">
                    <p class="intro">Weighted Quality Score</p>
                  </li>
                  <p class="intro" style="margin-left: 5%; margin-top: 2%; margin-bottom: 0%;">
                    Because AutoPhrase is built for extracting high-quality phrases from large text corpora, its quality evaluations of phrases in a single document might be unreliable. At the same time, the assessment based on POS makes the entity names always have high quality scores, although some entities have low frequencies and are not domain-specific.
                  </p>
                  <p class="intro" style="margin-left: 5%; margin-top: 2%; margin-bottom: 0%;">
                    To handle the biased quality evaluation, we apply weights to the quality scores of the phrases based on the phrases‚Äô corresponding quality scores in their domains according to the pre-trained domain datasets. Since the quality score is already standardized, ranging from 0 to 1, the most efficient way to apply weight is simply multiplying the quality scores: 
                  </p>
                  <p style="text-align: center; margin-top: 2%; margin-bottom: 2%;">
                    Quality<sub>weighted</sub> (x) = Quality<sub>document i</sub> (x) ‚àó Quality<sub>domain j</sub> (x)
                  </p>
                  <p class="intro" style="margin-left: 5%; margin-top: 0%;">
                    The weighted quality score not only could reassess the significance of the phrase according to both the input document and the domain, but also could filter the entities that are created by the document itself and would not contribute to finding other similar works.
                  </p>

                  <li style="margin-left: 2%;">
                    <p class="intro">Web Scraping</p>
                  </li>
                  <p class="intro" style="margin-left: 5%; margin-top: 2%; margin-bottom: 0%;">
                    To take advantage of the well-built recommender system in existing digital libraries, AutoPhrase has its own backend built with Flask. It is responsible for accepting keywords and fields of studies from the frontend and using them to search for scholarly articles by using the Semantic Scholar API.
                  </p>
                  <br>
                  <img src="{% static 'blog/webscrape.png' %}" alt="Workflow of the Application" height="70%" width="70%" style="display: block; margin-left: auto; margin-right: auto;" />
                  <p class="intro" style="margin-left: 5%; margin-top: 2%;">
                    The data returned from Semantic Scholar is a json string, which consists of lots of metadata of papers. The backend extracted useful ones, such as dates, abstracts and titles, formulating them into another json string and returned to the frontend. 
                  </p>
                </ul>

                <h2 id='Evaluation'>Evaluation</h2><br>
                <ul>
                  <li style="margin-left: 2%;">
                    <p class="intro">Experiments</p>
                  </li>
                  <p class="intro" style="margin-left: 5%; margin-top: 2%;">
                    We compared and contrasted it with similar web applications, including Jstor, Webtools and MonkeyLearn text analyzers.
                  </p>
                  <ol>
                    <p class="intro" style="margin-left: 5%; margin-top: -2%;">
                      Comparison between AutoLibrary and Webtools
                    </p>
                    <img src="{% static 'blog/experiment1.png' %}" alt="AutoLibrary vs. Webtools" height="80%" width="80%" style="display: block; margin-left: auto; margin-right: auto;" />
                    <img src="{% static 'blog/experiment1.png' %}" alt="AutoLibrary vs. Webtools" height="80%" width="80%" style="display: block; margin-left: auto; margin-right: auto;" />
                    <br>
                    <p class="intro" style="margin-left: 5%; margin-top: 2%; margin-bottom: 0%;">
                      We can see that the area under the precision-recall curve of AutoLibrary is bigger than that of Webtools in all eight domains. This means that AutoLibrary performs better than the Webtools analyzer across different domains. It makes sense intuitively since the latter one is very simple. Its results often contain non-quality phrases, such as ‚Äúof the‚Äù, ‚Äúcan be‚Äù, and etc. Moreover, in the domain of Quantitative Finance, where there were lots of mathematical equations, the Webtools analyzer failed to filter out symbols like ‚Äút<sub>s</sub>‚Äù.
                    </p>
                    <p class="intro" style="margin-left: 5%; margin-top: 2%;">
                      When comparing AutoPhrase and the Jstor analyzer, we used a histogram plot to compare their percentages of quality phrases in their extracted phrases.
                    </p>
                    <img src="{% static 'blog/extracted40.png' %}" alt="AutoLibrary vs. Jstor" height="80%" width="80%" style="display: block; margin-left: auto; margin-right: auto;" />
                    <br>
                    <p class="intro" style="margin-left: 5%; margin-top: 2%; margin-bottom: 0%;">
                      We can see that in all domains, AutoLibrary performs better than the Jstor analyzer. The main con of Jstor is that its recommendation is based on a fixed set of predefined topics. Therefore, it cannot make customized recommendations for specific papers. For example, when analyzing a statistics paper, it recommended ‚Äúdebt collection‚Äù, which doesn‚Äôt even exist in the original text. In contrast, AutoLibrary first extracts phrases from the input paper, which improves the contingency between the quality phrases and the original paper. 
                    </p>
                    <p class="intro" style="margin-left: 5%; margin-top: 2%; margin-bottom: 0%;">
                      Another big shortcoming of Jstor is that the topics it recommends are sometimes too general. Although they make sense in English, they don't qualify as quality phrases. For example, when analyzing the Computer Science paper, one of the phrases extracted is ‚Äúcomputer programming.‚Äù It doesn‚Äôt really help users since it‚Äôs too general for them to search for related papers.
                    </p>
                    <p class="intro" style="margin-left: 5%; margin-top: 2%; margin-bottom: 0%;">
                      Last but not least, Jstor doesn‚Äôt offer quality scores to recommended phrases, which means that users don‚Äôt know which phrases can best represent their input papers. AutoLibrary, on the other hand, ranks the top 5 phrases in order, so that users can have a better overview of the papers.
                    </p>
                    <p class="intro" style="margin-left: 5%; margin-top: 2%;">
                      Next we experimented with MonkeyLearn. Note that we only compared the top ten phrases from both AutoLibrary and MonkeyLearn, since the latter one only provides 10 keywords and phrases. The result comparison can be seen in the figure below. 
                    </p>
                    <img src="{% static 'blog/extracted10.png' %}" alt="AutoLibrary vs. MonkeyLearn" height="80%" width="80%" style="display: block; margin-left: auto; margin-right: auto;" />
                    <br>
                    <p class="intro" style="margin-left: 5%; margin-top: 2%;">
                      From the figure, we can see that AutoPhrase outperformed MonkeyLearn in all domains. One big disadvantage of MonkeyLearn we found is that it probably relies heavily on the frequency of phrases. Although it can extract some really meaningful phrases amongst its top 5 phrases, it also recommends some phrases that make no sense. For example, when analyzing the Mathematics paper, it extracted "a1 a2 a1", "a2 a1 a2" and "a1 a2 a0" amongst the top 10 phrases. We believe that AutoLibrary defeats MonkeyLearn by weighting phrases against domain knowledge pools, which eliminates the reckless ones.
                    </p>
                  </ol>
                  
                  <li style="margin-left: 2%;">
                    <p class="intro">Result Analysis</p>
                  </li>
                  <ol>
                    <li style="margin-left: 5%; margin-top: -2%; margin-bottom: 0%;">
                      <p class="intro"><i>Whether the model is able to differentiate similar papers published by the same author, while at the same time discovering their shared topics.</i></p>
                    </li>
                    <p class="intro" style="margin-left: 8%; margin-top: -2%; margin-bottom: 0%;">
                      We select 5 papers published by Professor Shang.
                    </p>
                    <img src="{% static 'blog/5papers.png' %}" alt="5 Papers Published by Professor Shang" height="60%" width="60%" style="display: block; margin-left: auto; margin-right: auto;" />
                    <br><br>
                    <img src="{% static 'blog/result_analysis1.png' %}" alt="Top 10 Quality Phrases from 5 Papers" height="80%" width="80%" style="display: block; margin-left: auto; margin-right: auto;" />
                    <br>
                    <p class="intro" style="margin-left: 8%; margin-top: 2%;">
                      After getting AutoPhrase results and applying weights, the result table shows that there are some phrases, such as "natural language," "pos tagging," "lstm crf," and "text corpora," shared across these 5 papers. At the same time, each of these papers has its own unique phrases, such as "cross validation" for CrossWeigh, "knowledge base" for AutoPhrase, "sequence labeling" for LM-LSTM-CRF, "distant supervision" for AutoNER, and "bipartite graph" for SetExpan. It proves that our model is able to differentiate similar papers published by the same author, while at the same time discovering their shared topics.
                    </p>
                    <li style="margin-left: 5%; margin-top: -2%; margin-bottom: 0%;">
                      <p class="intro"><i>Whether the model is able to give precise results compared to manual labeling.</i></p>
                    </li>
                    <p class="intro" style="margin-left: 8%; margin-top: -2%; margin-bottom: 0%;">
                      We annotate the weighted results by manual checking and labeling whether the phrases can actually represent the paper. 
                    </p>
                    <img src="{% static 'blog/curve.png' %}" alt="Precision-Recall Curve" height="70%" width="70%" style="display: block; margin-left: auto; margin-right: auto;" />
                    <img src="{% static 'blog/result_analysis2.png' %}" alt="Accuracy Compared to Manuel Labeling" height="80%" width="80%" style="display: block; margin-left: auto; margin-right: auto;" />
                    <p class="intro" style="margin-left: 8%; margin-top: 2%;">
                      Accuracy is higher for phrases with a higher quality score. Both the precision-recall curve and the accuracy compared to manual labeling show that our model is able to give precise results compared to manual labeling.
                    </p>
                  </ol>
                </ul>
                <hr><br>

                <h2 id='Advantages'>Advantages</h2><br>
                <img src="{% static 'blog/advantage.png' %}" alt="Advantages" height="70%" width="70%" style="display: block; margin-left: auto; margin-right: auto;" />
                <p class="intro">
                  There are several advantages of AutoLibrary:
                </p>
                <ul>
                  <ol>
                    <li style="margin-left: 5%; margin-top: -2%; margin-bottom: 0%;">
                      <p class="intro">
                        Accurate: AutoLibrary is able to give precise results compared to other text analyzers as well as manual labeling.
                      </p>
                    </li>
                    <li style="margin-left: 5%; margin-top: -2%; margin-bottom: 0%;">
                      <p class="intro">
                        Specific: AutoLibrary is able to differentiate similar papers published by the same author while at the same time discovering their shared topics.
                      </p>
                    </li>
                    <li style="margin-left: 5%; margin-top: -2%; margin-bottom: 0%;">
                      <p class="intro">
                        Domain Independent: AutoLibrary utilizes AutoPhrase which is a domain-independent phrase mining method developed by Jingbo Shang et al. (2018) that can automatically extract quality phrases from the input paper.
                      </p>
                    </li>
                    <li style="margin-left: 5%; margin-top: -2%;">
                      <p class="intro">
                        Customizable: After inputting a paper, the user can select a field of study to start the first search on Semantic Scholar using the top three keywords. After that, users can customize the selection of the high-quality phrases or enter their own keywords to explore other related works.
                      </p>
                    </li>
                  </ol>
                </ul>     
                <br>
              </div>
            </div>
          </div>
          <div id="sidebar">
            <div id="logo"> <img src="{% static 'autolibrary/images/logo.png' %}" alt="Nautica X" width="180px" height="110px"/> </div>
            <!-- <div id="contents" style="position: fixed;"> -->
            <div id="contents">
              <h4>Contents</h4>
              <ul id="content_list" class="side-nav">
                <li><a href="#Introduction">Introduction</a></li>
                <li><a href="#Methodology">Methodology</a></li>
                <li><a href="#Evaluation">Evaluation</a></li>
                <li><a href="#Advantages">Advantages</a></li>
              </ul>
            </div>
          </div>
        </div>
        <div id="footer">
          <ul id="footer-nav">
            <li><a href="#">AutoLibrary</a></li>
            <li><a href="http://yichunren.pythonanywhere.com/blog">Blog</a></li>
            <li><a target="_blank" rel="noopener noreferrer" href="https://github.com/jfan1998/AutoLibrary">Code</a></li>
            <li class="last"><a href="#">Contact Us</a></li>
          </ul>
          <p class="copyright">Copyright 2021 Yichun Ren & Jiayi Fan & Bingqi Zhou</p>
        </div>
      </div>
    </div>
  </body>
</html>
<script>
  $(function() {
    var $sidebar   = $("#contents"), 
        $window    = $(window),
        offset     = $sidebar.offset(),
        topPadding = 50;

    $window.scroll(function() {
        if ($window.scrollTop() > offset.top) {
            $sidebar.stop().animate({
                marginTop: $window.scrollTop() - offset.top + topPadding
            });
        } else {
            $sidebar.stop().animate({
                marginTop: 0
            });
        }
    });
  });
</script>